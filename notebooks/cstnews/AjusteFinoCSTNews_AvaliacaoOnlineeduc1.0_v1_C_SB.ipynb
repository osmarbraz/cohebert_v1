{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AjusteFinoCSTNews_AvaliacaoOnlineeduc1.0_v1_C_SB.ipynb","provenance":[{"file_id":"1Er23iD96x_SzmRG8md1kVggbmz0su_Q5","timestamp":1602332127662}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8bd516b3bc7a4c6887b3b207cbd65ea3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b47d5968ae7a4c6896385dde29ec0f0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f2917dbd6694ec989f80d29acdd1f3f","IPY_MODEL_f495ba78db1f467d9adf5405f8761e12"]}},"b47d5968ae7a4c6896385dde29ec0f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f2917dbd6694ec989f80d29acdd1f3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e0dce945cd0403aa3b1027348ccdc62","_dom_classes":[],"description":"Épocas: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2462aadeceb3402cb4a7ef8c432cd086"}},"f495ba78db1f467d9adf5405f8761e12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14596a02a6a94df584b7f9b436b522e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [11:35&lt;00:00, 695.11s/épocas]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad29b5452e3041289c3df77a24158304"}},"4e0dce945cd0403aa3b1027348ccdc62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2462aadeceb3402cb4a7ef8c432cd086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14596a02a6a94df584b7f9b436b522e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad29b5452e3041289c3df77a24158304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8093b088d66c4c318e0809591f27c9de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_63c73f6b99914e58918e2e57e23364e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_78db7cbe130140f697f0165624718fe8","IPY_MODEL_54e74d94b5fe42609e8008436f08d744"]}},"63c73f6b99914e58918e2e57e23364e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78db7cbe130140f697f0165624718fe8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ce8506eba3b4720ad5de036ca05803c","_dom_classes":[],"description":"Epoca 1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2490,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2490,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e5966dd1a1d45618b535627cd92b683"}},"54e74d94b5fe42609e8008436f08d744":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c35130911fa49f98b459d114b26b3c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2490/2490 [11:05&lt;00:00,  3.74lotes/s, loss=0.00322]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_867d6220a0a7435a9b82051b64d9422c"}},"4ce8506eba3b4720ad5de036ca05803c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e5966dd1a1d45618b535627cd92b683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c35130911fa49f98b459d114b26b3c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"867d6220a0a7435a9b82051b64d9422c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b4b4d435379436db5101fadd639f69e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b125c21282db47869fc57b1206507660","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72a595c1b108413194eff8ffefe00391","IPY_MODEL_0291ac0f874f46f39d0e2b8afa96209a"]}},"b125c21282db47869fc57b1206507660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72a595c1b108413194eff8ffefe00391":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e9f277e9fd24496b65405ab25794139","_dom_classes":[],"description":"Lotes : 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fa151958c1941f5bd2ff2207b66c853"}},"0291ac0f874f46f39d0e2b8afa96209a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df844f770583461581032a21eb1370cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2805/2805 [02:50&lt;00:00, 16.48lotes/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cbda363d70047a598ad6bfef0c23a41"}},"2e9f277e9fd24496b65405ab25794139":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1fa151958c1941f5bd2ff2207b66c853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df844f770583461581032a21eb1370cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cbda363d70047a598ad6bfef0c23a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1JNgd_Bc55AB"},"source":["#Ajuste fino do conjunto de dados CSTNews usando BERT e validação com os dados do OnlineEduc 1.0\n","\n","\n","Realiza o ajuste do MCL BERT pré-treinado usando o conjunto de dados CSTNews e a avaliação com o conjunto de dados OnlineEduc 1.0.\n","\n","- Realiza o ajuste fino nos dados dos dados CSTNEWS.\n","- Utiliza Lotes Inteligentes para otimizar o tempo de execução de treinamento.\n","- Divide o dataset em 70% para treino e 30% para avaliação.\n","- Salva o modelo ajustado para reaproveitamento,\n","- A seção 2 - parametrização define os argumentos da execução.\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n","\n","**Artigo padding dinâmico:**\n","https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e"]},{"cell_type":"markdown","metadata":{"id":"P3G9t8llcrKz"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do notebook."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","metadata":{"id":"rcTEKloUn-VK"},"source":["import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicioProcessamento = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOHCMMDsiyZg","executionInfo":{"status":"ok","timestamp":1626387881899,"user_tz":180,"elapsed":6,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"f2131113-7565-4fcf-cc00-d4f4f38b880d"},"source":["print(\"  Tempo de início de processamento:  {:} (h:mm:ss)\".format(inicioProcessamento))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Tempo de início de processamento:  1626387881.422135 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-DnPWIRHfq7V"},"source":["## 1.2 Tratamento de logs"]},{"cell_type":"code","metadata":{"id":"54St2CZf5lWv"},"source":["# Biblioteca de logging\n","import logging\n","\n","# Formato da mensagem\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.3 Identificando o ambiente Colab"]},{"cell_type":"code","metadata":{"id":"YMiH0E3OnRa1"},"source":["# Se estiver executando no Google Colaboratory\n","import sys\n","\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = 'google.colab' in sys.modules"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rceIwWa7UmFZ"},"source":["## 1.4 Biblioteca de limpeza de tela"]},{"cell_type":"code","metadata":{"id":"PXTEvmuhUmjO"},"source":["from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJzK1XjCnZak"},"source":["## 1.5 Conecta ao Google Drive\n","\n","É necessário existir a pasta '/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS_MD_CV_10/Resultados/' para receber os resutlados do notebook."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz3RRgR-nZan","executionInfo":{"status":"ok","timestamp":1626387902536,"user_tz":180,"elapsed":20640,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"8c55804a-d17b-4811-f7a2-01d80493388f"},"source":["# Monta o Google Drive para esta instância de notebook.\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.6 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626387911089,"user_tz":180,"elapsed":8556,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"31a6466c-0d3a-4fb7-c15e-e27d65281ce9"},"source":["!pip install --upgrade wandb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f6/91c07f54c2162854f5028aaa13f576ca17a3bc0cf6da02c2ad5baddae128/wandb-0.10.33-py2.py3-none-any.whl (1.8MB)\n","\r\u001b[K     |▏                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 19.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 15.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 9.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 7.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184kB 7.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194kB 7.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204kB 7.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 215kB 7.7MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 245kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 266kB 7.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 276kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 286kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 296kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 327kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 337kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 348kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 358kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 378kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 399kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 409kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 430kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 440kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 450kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 460kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 471kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 481kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 491kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 522kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 532kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 542kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 552kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 563kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 573kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 593kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 604kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 614kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 634kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 645kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 655kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 665kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 675kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 686kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 696kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 706kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 716kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 727kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 747kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 757kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 768kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 778kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 788kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 798kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 808kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 819kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 829kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 839kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 860kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 870kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 880kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 890kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 901kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 911kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 921kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 931kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 942kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 952kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 962kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 972kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 983kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 993kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.7MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 7.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 12.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/75fad31fff378871c462745ce724b3701a6acad17028d79476ec2545e40f/sentry_sdk-1.3.0-py2.py3-none-any.whl (133kB)\n","\u001b[K     |████████████████████████████████| 143kB 39.5MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n","\u001b[K     |████████████████████████████████| 174kB 38.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied, skipping upgrade: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[?25hCollecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: pathtools, subprocess32\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=1210a941c2126f1478c48bd317bfb85e2bf2614479b51913476eec493de47273\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=7ac6f1f587e83753df4115b76764cac45c33ca04241779768663a7318c231824\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","Successfully built pathtools subprocess32\n","Installing collected packages: configparser, pathtools, shortuuid, subprocess32, sentry-sdk, docker-pycreds, smmap, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.33\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6c7JaP-LM2bW"},"source":["Login via linha de comando"]},{"cell_type":"code","metadata":{"id":"WOvp48GnMuvM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626387912259,"user_tz":180,"elapsed":1172,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"90082043-dc1c-42a6-878b-d0d6d381106e"},"source":["!wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.7 Instalação BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. "]},{"cell_type":"code","metadata":{"id":"-XeR8Sbz0B5x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626387917272,"user_tz":180,"elapsed":5014,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"3d97d2b2-d86a-4102-c593-1eb92f6733ff"},"source":["!pip install -U transformers==4.5.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==4.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 9.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.0.12)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 45.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.6.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 40.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.1) (3.5.0)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ne84ggOIwvlN"},"source":["## 1.8 Recupera o coebert do Github"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HasDDV1Il1t","executionInfo":{"status":"ok","timestamp":1626387921722,"user_tz":180,"elapsed":4457,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"0d572918-1561-4f12-c236-98ca1ade3f9f"},"source":["tokengit = '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'\n","nomeusuario = 'osmarbraz'\n","repositorio = 'coebert_v1.git'\n","!git clone https://{tokengit}@github.com/{nomeusuario}/{repositorio}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'coebert_v1'...\n","remote: Enumerating objects: 2764, done.\u001b[K\n","remote: Counting objects: 100% (2764/2764), done.\u001b[K\n","remote: Compressing objects: 100% (1452/1452), done.\u001b[K\n","remote: Total 2764 (delta 1662), reused 1931 (delta 1259), pack-reused 0\u001b[K\n","Receiving objects: 100% (2764/2764), 23.02 MiB | 13.51 MiB/s, done.\n","Resolving deltas: 100% (1662/1662), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZYrhaS9zaWmp"},"source":["#Muda o diretório corrente para a pasta clonada\n","import sys\n","sys.path.append('./coebert_v1/coebert')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3MgI7Ldb9ce"},"source":["# Import de bibliotecas\n","from util.utilmodulo import *\n","from util.utiltempo import *\n","from util.utilarquivo import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.9 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtaYZmc3Vbfj","executionInfo":{"status":"ok","timestamp":1626387929251,"user_tz":180,"elapsed":7536,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"0bab801e-d580-4623-f44f-b1708b4c7316"},"source":["# Importando a biblioteca\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == '/device:GPU:0':\n","    print('Encontrei GPU em: {}'.format(device_name))\n","else:\n","    print('Dispositivo GPU não encontrado')\n","    #raise SystemError('Dispositivo GPU não encontrado')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Encontrei GPU em: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla V100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla V100-SXM2-16GB(Pro)\n","- 2o Tesla P100-PCIE-16GB\n","- 3o Tesla T4\n","- 4o Tesla P4 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)\n","- 5o Tesla K80 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrjqDO6nWa8J","executionInfo":{"status":"ok","timestamp":1626387933296,"user_tz":180,"elapsed":4047,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e4b12856-52df-40a3-ed2b-9499dc517e3d"},"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","device = getDeviceGPU()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Existem 1 GPU(s) disponíveis.\n","Iremos usar a GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","metadata":{"id":"1iC5-pSAVh7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626387933296,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e3ab631a-f973-4a9e-8bc5-2e4d45595637"},"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","print('Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"')\n","  print('e selecione High-RAM. Então, execute novamente está célula')\n","else:\n","  print('Você está usando um ambiente de execução de memória RAM alta!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","e selecione High-RAM. Então, execute novamente está célula\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"code","metadata":{"id":"oJ15-ylRRRdD"},"source":["# Importando as bibliotecas.\n","from transformers import TrainingArguments\n","\n","# Definição dos parâmetros de Treinamento\n","training_args = TrainingArguments(\n","    # AjusteFinoMoodle_v1_C_SB_HT = nome do notebook\n","    # E = número de épocas\n","    # lr = taxa de aprendizagem\n","    # b = lotes de treino e avaliação    \n","    output_dir = 'AjusteFinoCSTNews_AvaliacaoMoodle_v1_C_SB_E_4_lr_1_b_4_8',  \n","    save_steps = 0,    \n","    seed = 42,\n","    num_train_epochs = 1, # Intervalo de valores: 2, 3, 4\n","    learning_rate = 1e-5, # Intervalo de valores: 1e-5, 2e-5, 3e-5, 4e-5, 5e-5 \n","    gradient_accumulation_steps = 1,\n","    per_device_train_batch_size = 4, \n","    per_device_eval_batch_size = 8,        \n","    evaluation_strategy = 'epoch'\n",")\n","\n","# Import de bibliotecas\n","from bert.bertarguments import ModeloArgumentosClassificacao\n","\n","# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosClassificacao(     \n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",    \n","    #pretrained_model_name_or_path = 'bert-base-multilingual-cased',\n","    do_lower_case = False,   # default True\n","    num_labels = 2,\n","    output_attentions = False,    # default False\n","    output_hidden_states = False, # default False\n","    optimizer = 'AdamW',\n","    use_wandb = False,\n","    salvar_modelo_wandb = False,    \n","    salvar_modelo = False,\n","    salvar_classificacao = False, # Salva o resultado classificações\n","    salvar_avaliacao = False # Salva o resultado da avaliação das classificações\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aEyME6nxO_V"},"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT =  getTamanhoBERT(model_args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gk9I_DX5coOI"},"source":["# 3 BERT"]},{"cell_type":"markdown","metadata":{"id":"e2Slpfk-dIUw"},"source":["## Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **'neuralmind/bert-base-portuguese-cased'**\n","* **'neuralmind/bert-large-portuguese-cased'**"]},{"cell_type":"code","metadata":{"id":"04TdVv56TB73","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626387988730,"user_tz":180,"elapsed":55442,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"c041aabf-e809-40a6-f325-154eb59092ea"},"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pasta do /content/modelo pronta!\n","Usando modelo pré-treinado de download ou comunidade\n","Carregando o modelo BERT do diretório /content/modelo para classificação.\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/modelo were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/modelo and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Carregando o tokenizador BERT do diretório /content/modelo...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wJdbTzeejhOE"},"source":["# 4 Treino"]},{"cell_type":"markdown","metadata":{"id":"G7MlEvcbuyCh"},"source":["## 4.1 wandb\n","\n","https://wandb.ai/osmar-braz/ajustefinocstnews_v1_c_sb_holdout/table?workspace=user-osmar-braz"]},{"cell_type":"markdown","metadata":{"id":"unllEBZQuLkk"},"source":["### Função de inicialização wandb"]},{"cell_type":"code","metadata":{"id":"S0ky2-JguMBG"},"source":["def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    # Importando a biblioteca.\n","    import wandb\n","\n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_avaliacaomoodle_v1_c_sb\", name=training_args.output_dir)\n","\n","    # Atualiza os parâmetros de treinamento no wandb.\n","    wandb.config.update(training_args)\n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","\n","    # Registra os parämetros não literais do model_args.\n","    wandb.log({\"max_seq_len\": model_args.max_seq_len})\n","    wandb.log({\"do_lower_case\": model_args.do_lower_case})\n","    wandb.log({\"output_hidden_states\": model_args.output_hidden_states})\n","\n","    return wandb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrKMXRNm7OI6"},"source":["### Inicialização wandb\n","\n"]},{"cell_type":"code","metadata":{"id":"1UDfEld07QRm"},"source":["wandb = inicializacaoWandb()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJzDVmgts4nd"},"source":["## 4.2 Colab GPU\n","\n","Conecta o modelo carregado do BERT a GPU para reduzir o tempo de processamento."]},{"cell_type":"markdown","metadata":{"id":"RlNQLdiNySKQ"},"source":["### Conectando GPU ao modelo"]},{"cell_type":"code","metadata":{"id":"46lfiIZfySZd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388000245,"user_tz":180,"elapsed":11525,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"8a2d10d3-6073-4ccf-8e7d-5e288e2c9eaa"},"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","model = conectaGPU(model, device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pytorch rodando o modelo na GPU\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7-aD0Bl2CN4E"},"source":["## 4.3 Arquivo dos dados de treino"]},{"cell_type":"markdown","metadata":{"id":"snzt2Fd85h6t"},"source":["### Carregamento dos dados"]},{"cell_type":"code","metadata":{"id":"lI1CcD9z5kKk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388062148,"user_tz":180,"elapsed":61930,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"5726d962-73bf-447a-f2c0-2d2c09defa8d"},"source":["# Import de bibliotecas\n","from conjuntodedados.dadoscstnewsclassificacao import *\n","\n","# Carrega os dados\n","dfdados = getConjuntoDeDadosClassificacao(model_args, None, tokenizer)\n","\n","print(len(dfdados))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Realizando o download do meu OneDrive.\n","Geraçao de pares de documentos concluído: 5020\n"],"name":"stdout"},{"output_type":"stream","text":["2021-07-15 22:27:41,194 : INFO : NumExpr defaulting to 2 threads.\n"],"name":"stderr"},{"output_type":"stream","text":["9960\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0tntNQtk6dwx"},"source":["### Divisão do conjunto de dados\n","\n","Não tem divisão pois iremos utilizar todo o conjunto para treinamento."]},{"cell_type":"code","metadata":{"id":"a8Rq2VmQHuGU"},"source":[" #dfdados_train, dfdados_test = divisaoConjuntoDados(dfdados, percentualDivisao=0.3, classeStratify='classe'):\n"," \n"," dfdados_train = dfdados"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iotmxm9qHuGV"},"source":["Vamos extrair os dados do arquivo do TensorFlow, para termos apenas tipos simples de Python.\n","\n","Não foi usada a classe tensorflow_datasets, portanto não foi necessária a extração, somente a divisão em listas separadas."]},{"cell_type":"markdown","metadata":{"id":"NRFutyKu6pNc"},"source":["### Seleciona as colunas de treino"]},{"cell_type":"code","metadata":{"id":"JfnQJDY_6qey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388062149,"user_tz":180,"elapsed":32,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"c9a21b6a-fd93-4033-ec61-21835a961549"},"source":["# Import das bibliotecas.\n","import numpy as np\n","\n","# Pega as listas de documentos e seus rótulos para o treino\n","documentos_treino = dfdados_train.documento.values\n","classes_treino = dfdados_train.classe.values\n","documentoids_treino = dfdados_train.id.values\n","\n","# Mostra algumas estatísticas.\n","print('{:,} Amostras de Treino'.format(len(documentos_treino)))\n","print('{:,} Rótulos de Treino'.format(len(classes_treino)))\n","print('Rótulos: {}'.format(np.unique(classes_treino)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9,960 Amostras de Treino\n","9,960 Rótulos de Treino\n","Rótulos: [0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 4.4 Análise treino"]},{"cell_type":"markdown","metadata":{"id":"rX54hJPRHFr7"},"source":["Usaremos os pandas para analisar o conjunto de dados e examinar algumas de suas propriedades e pontos de dados."]},{"cell_type":"markdown","metadata":{"id":"08pO03Ff1BjI"},"source":["Atributos da lista:\n","0. \"arquivo\"\n","1. \"documento\"\n","2. \"classe\" (1-Original, 0-Permutado)\n"]},{"cell_type":"code","metadata":{"id":"j2WkBWvtHFr7","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1626388062150,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"31acfbe2-640b-471f-ce34-03aafd6be5f8"},"source":["dfdados_train.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7220</th>\n","      <td>C19_Extrato_6.txt</td>\n","      <td>BUENOS AIRES - Maradona voltou a ter problemas...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3734</th>\n","      <td>C25_Extrato_4.txt</td>\n","      <td>Em meio ao Pan-americano do Rio de Janeiro, o ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7458</th>\n","      <td>C49_Extrato_3.txt</td>\n","      <td>RIO - O presidente Luiz Inácio Lula da Silva c...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5037</th>\n","      <td>C29_Extrato_3_Perm_18.txt</td>\n","      <td>A grande maioria dos processos referentes a ac...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7714</th>\n","      <td>C16_Extrato_4.txt</td>\n","      <td>Os deputados acusados de envolvimento na máfia...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             id  ... classe\n","7220          C19_Extrato_6.txt  ...      1\n","3734          C25_Extrato_4.txt  ...      1\n","7458          C49_Extrato_3.txt  ...      1\n","5037  C29_Extrato_3_Perm_18.txt  ...      0\n","7714          C16_Extrato_4.txt  ...      1\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"puijlGwiHFr9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388062150,"user_tz":180,"elapsed":20,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"99dd3928-1ab4-494a-8500-576d3a3c9940"},"source":["# Mostra o número de documento de treino.\n","print('Número de documentos de treino: {:,}\\n'.format(dfdados_train.shape[0]))\n","\n","# Informações do DataFrame.\n","print(dfdados_train.info())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Número de documentos de treino: 9,960\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9960 entries, 0 to 9959\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         9960 non-null   object\n"," 1   documento  9960 non-null   object\n"," 2   classe     9960 non-null   int64 \n","dtypes: int64(1), object(2)\n","memory usage: 233.6+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FdJhSquUzo68"},"source":["### Distribuição das classes\n","\n","O dataset está bem balanceado, o que nos conduz a utilizar acurácia como métrica."]},{"cell_type":"code","metadata":{"id":"AV7n7pKGzfOG","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1626388062150,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"99ec72a2-733d-4260-99e6-7280c9825c9f"},"source":["dfdados_train.groupby('classe').count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>classe</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4980</td>\n","      <td>4980</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4980</td>\n","      <td>4980</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id  documento\n","classe                 \n","0       4980       4980\n","1       4980       4980"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"7FYof6pYz9ja","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388062150,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"262bd798-ba15-47f1-c437-66c89824f004"},"source":["# Informações do DataFrame.\n","print(dfdados_train.info())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9960 entries, 0 to 9959\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         9960 non-null   object\n"," 1   documento  9960 non-null   object\n"," 2   classe     9960 non-null   int64 \n","dtypes: int64(1), object(2)\n","memory usage: 233.6+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aRp4O7D295d_"},"source":["### Conjunto de dados em Treinamento"]},{"cell_type":"code","metadata":{"id":"6AeCq7cbo5Mu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388062151,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"250ac53c-6733-4cdb-ed33-b7bbdd7caa27"},"source":["# Mostra o resultado dos dados carregados.\n","print(\"Total do conjunto de dados          : {}.\".format(len(dfdados)))\n","print(\"Total do conjunto de dados de treino: {}.\".format(len(documentos_treino)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 9960.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"--c3qOsWSSfQ"},"source":["## 4.5 Arquivo dos dados avaliacao"]},{"cell_type":"markdown","metadata":{"id":"djlNBt70SSfb"},"source":["### Carregamento dos dados"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iqWwtn0SSfb","executionInfo":{"status":"ok","timestamp":1626388084316,"user_tz":180,"elapsed":22175,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"34bd17f2-dd93-4f90-8c71-cc2f023c528c"},"source":["# Import de bibliotecas\n","from conjuntodedados.dadosonlineducclassificacao import *\n","\n","# Carrega os dados\n","dfdados = getConjuntoDeDadosClassificacao(model_args, tokenizer)         \n","\n","print(len(dfdados))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Realizando o download do Google Drive.\n","TERMINADO GERAÇÃO PARES: 11220\n","22440\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BnQfhbo-SSfe"},"source":["### Divisão do conjunto de dados"]},{"cell_type":"code","metadata":{"id":"fZwcfmfIPs1t"},"source":[" #dfdados_train, dfdados_test = divisaoConjuntoDados(dfdados)\n"," dfdados_test = dfdados"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMLCdOMRSSfe"},"source":["Vamos extrair os dados do arquivo do TensorFlow, para termos apenas tipos simples de Python.\n","\n","Não foi usada a classe tensorflow_datasets, portanto não foi necessária a extração, somente a divisão em listas separadas."]},{"cell_type":"markdown","metadata":{"id":"bHcN8zf4QHUG"},"source":["### Seleciona as colunas de teste"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPWgwot2HuGW","executionInfo":{"status":"ok","timestamp":1626388084317,"user_tz":180,"elapsed":23,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"f007adb5-cef5-4e66-a4fc-bad537df3e16"},"source":["# Import das bibliotecas.\n","import numpy as np\n","\n","# Pega as listas de documentos e seus rótulos para o treino\n","documentos_teste = dfdados_test.documento.values\n","classes_teste = dfdados_test.classe.values\n","documentoids_teste = dfdados_test.id.values\n","\n","# Mostra algumas estatísticas.\n","print('{:,} Amostras de Teste'.format(len(documentos_teste)))\n","print('{:,} Rótulos de Teste'.format(len(classes_teste)))\n","print('Rótulos: {}'.format(np.unique(classes_teste)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["22,440 Amostras de Teste\n","22,440 Rótulos de Teste\n","Rótulos: [0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kCXgM-sxSSff"},"source":["## 4.6 Análise avaliação"]},{"cell_type":"markdown","metadata":{"id":"dwfRyHpDSSff"},"source":["Usaremos os pandas para analisar o conjunto de dados e examinar algumas de suas propriedades e pontos de dados."]},{"cell_type":"markdown","metadata":{"id":"16LsLxcOSSff"},"source":["Atributos da lista:\n","0. \"arquivo\"\n","1. \"documento\"\n","2. \"classe\" (1-Original, 0-Permutado)\n"]},{"cell_type":"code","metadata":{"id":"Q10hRk3XICB7","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1626388084317,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"4b9bc69b-6151-4c4e-82c4-34ea517770d6"},"source":["dfdados_test.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2771</th>\n","      <td>Documento_56279_Perm_5.txt</td>\n","      <td>Bom dia queridos colegas! Há alguma versão sug...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18302</th>\n","      <td>Documento_44533.txt</td>\n","      <td>Ola, fiquei com dúvidas na questao 29. Se o ta...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16454</th>\n","      <td>Documento_62934.txt</td>\n","      <td>Bom dia Jacinta, tudo bem? Uma dica: nos próxi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4627</th>\n","      <td>Documento_62919_Perm_13.txt</td>\n","      <td>Assim você pode avaliar seu entendimento no as...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16630</th>\n","      <td>Documento_115084.txt</td>\n","      <td>Boa Tarde, Professores. Quem escolhe a Unidade...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                id  ... classe\n","2771    Documento_56279_Perm_5.txt  ...      0\n","18302          Documento_44533.txt  ...      1\n","16454          Documento_62934.txt  ...      1\n","4627   Documento_62919_Perm_13.txt  ...      0\n","16630         Documento_115084.txt  ...      1\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"DwPzTkbnICCD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388084318,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e39bfec5-72b5-49a2-cd52-aa3b0c974b97"},"source":["# Mostra o número de documento de treino.\n","print('Número de documentos de teste: {:,}\\n'.format(dfdados_test.shape[0]))\n","\n","# Informações do DataFrame.\n","print(dfdados_test.info())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Número de documentos de teste: 22,440\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 22440 entries, 0 to 22439\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         22440 non-null  object\n"," 1   documento  22440 non-null  object\n"," 2   classe     22440 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 526.1+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nAu53BtuSSfg"},"source":["### Distribuição das classes\n","\n","O dataset está bem balanceado, o que nos conduz a utilizar acurácia como métrica."]},{"cell_type":"code","metadata":{"id":"pzqyERUfIK2P","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1626388084318,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"cad362dd-d30c-4f72-c595-9cd50f70a1b9"},"source":["dfdados_test.groupby('classe').count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>classe</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11220</td>\n","      <td>11220</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11220</td>\n","      <td>11220</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           id  documento\n","classe                  \n","0       11220      11220\n","1       11220      11220"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"DE0ek_xDKiYC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388084318,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"5ec327cb-7399-4fc7-ff8f-14a641c2ac66"},"source":["# Informações do DataFrame.\n","print(dfdados_test.info())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 22440 entries, 0 to 22439\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         22440 non-null  object\n"," 1   documento  22440 non-null  object\n"," 2   classe     22440 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 526.1+ KB\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G6Mcn1uKSSfh"},"source":["### Conjunto de dados em Avaliação"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4AtmK5iSSfh","executionInfo":{"status":"ok","timestamp":1626388084319,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"b5615278-feea-4ede-eb68-f91757fe6cca"},"source":["# Mostra o resultado dos dados carregados.\n","print(\"Total do conjunto de dados          : {}.\".format(len(dfdados)))\n","print(\"Total do conjunto de dados de teste : {}.\".format(len(documentos_teste)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total do conjunto de dados          : 22440.\n","Total do conjunto de dados de teste : 22440.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8bwa6Rts-02-"},"source":["## 4.7 Treinando o modelo de classificação"]},{"cell_type":"markdown","metadata":{"id":"1AQ-E1QPJqJp"},"source":["### Otimizador e Agendador de Taxas de Aprendizado/Optimizer & Learning Rate Scheduler\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PBi41traJqJp"},"source":["Agora que temos nosso modelo carregado, precisamos pegar os hiperparâmetros de treinamento no modelo armazenado.\n","\n","Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (no Apêndice A.3 do [artigo BERT](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","> - **Tamanho do lote(Batch size):** 16, 32\n","- **Taxa de aprendizado (Adam):** 5e-5, 3e-5, 2e-5\n","- **Número de épocas:** 2, 3, 4\n","\n","O parâmetro epsilon `eps = 1e-6` é\" um número muito pequeno para impedir qualquer divisão por zero na implementação \"(a partir de [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n","\n","Você pode encontrar a criação do otimizador do AdamW em `run_glue.py` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."]},{"cell_type":"markdown","metadata":{"id":"MKecsl5K3LR9"},"source":["### Função carrega otimizador"]},{"cell_type":"code","metadata":{"id":"ajnrdhF63N-r"},"source":["def carregaOtimizador():\n","\n","  '''\n","    Esta função carrega o otimizador utilizado no agendador de aprendizado.\n","  '''\n","  \n","  # Import das bibliotecas.\n","  from transformers import AdamW\n","\n","  # Nota: AdamW é uma classe da biblioteca huggingface (ao contrário de pytorch).\n","  # Eu acredito que o 'W' significa 'Correção de redução de peso \"\n","  optimizer = AdamW(model.parameters(),\n","                  lr = training_args.learning_rate, # (ou alfa) A taxa de aprendizado a ser usada. - default é 3e-5\n","                  # betas = (0.9, 0.999), # (beta1, beta2) - default é (0.9, 0.999)\n","                    # beta1 é taxa de decaimento exponencial para as estimativas do primeiro momento. \n","                    # beta2 é taxa de decaimento exponencial para as estimativas do segundo momento. Este valor deve ser definido próximo a 1,0 em problemas com gradiente esparso (por exemplo, PNL e problemas de visão de computacional)\n","                  # eps = 1e-6, #  É um número muito pequeno para evitar qualquer divisão por zero na implementação - default é 1e-6.\n","                  # weight_decay = 0.0, # Correção de redução de peso. - default é 0.0\n","                    # A redução da taxa de aprendizagem também pode ser usada com Adam. A taxa de decaimento é atualizada a cada época para a demonstração da regressão logística.\n","                  # correct_bias = True #  Se não deve corrigir o viés(bias) no Adam mudar para False.- default é True\n","                )\n","  \n","  return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gB7S3ku3UtE"},"source":["### Carregando otimizador"]},{"cell_type":"code","metadata":{"id":"GLs72DuMODJO"},"source":["optimizer = carregaOtimizador()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N-Aqb27R3cci"},"source":["### Função carrega agendador"]},{"cell_type":"markdown","metadata":{"id":"W2MT7UK84srM"},"source":["A função **get_linear_schedule_with_warmup** cria um agendador com uma taxa de aprendizado que diminua linearmente da taxa de aprendizagem inicial definido no otimizador até 0, após um período de aquecimento durante o qual ele aumenta linearmente de 0 para a taxa de aprendizagem inicial definido no otimizador.\n","\n","Se `num_warmup_steps=0` e `weight_decay=0`(otimizador) não ocorre a etapa de aquecimento."]},{"cell_type":"code","metadata":{"id":"XMCaS1VqNr5y"},"source":["def carregaAgendador():\n","\n","  '''\n","    Esta função carrega o agendador com um taxa de aprendizado que diminua linearmente até 0.\n","  '''\n","\n","  # Import das bibliotecas.\n","  from transformers import get_linear_schedule_with_warmup\n","\n","  # O número total de etapas de ajuste fino é [número de lotes] x [número de épocas].\n","  # (Observe que este não é o mesmo que o número de amostras de ajuste fino).\n","  total_etapas = len(documentos_treino) * training_args.num_train_epochs\n","\n","  #Cria o agendador de taxa de aprendizagem.\n","  scheduler = get_linear_schedule_with_warmup(optimizer, # O otimizador para o qual agendar a taxa de aprendizado.\n","                                            num_warmup_steps = 0, # O número de etapas para a fase de aquecimento. Valor default value em run_glue.py\n","                                            num_training_steps = total_etapas) # O número total de etapas de treinamento.\n","\n","\n","  print(\"Total de etapas: {}\".format(total_etapas))\n","\n","  return scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zq-CMoxE3f9m"},"source":["### Carrega agendador"]},{"cell_type":"code","metadata":{"id":"gW1WhYvQ3gIy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388084320,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"2c36e2e3-a539-4811-fa64-eac492f78735"},"source":["scheduler = carregaAgendador()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total de etapas: 9960\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kwVBCyXWJqJq"},"source":["### Função cria lotes inteligentes"]},{"cell_type":"code","metadata":{"id":"TTxmZc60JqJq"},"source":["def cria_lotes_inteligentes1(documentos, classes, documentoids, batch_size):\n","    '''\n","    Esta função combina todos os passos para preparar os lotes.\n","    '''\n","    print('Criando Lotes Inteligentes de {:,} amostras com tamanho de lote {:,}...\\n'.format(len(documentos), batch_size))\n","\n","    # ============================\n","    #   Tokenização & Truncamento\n","    # ============================\n","\n","    input_ids_completos = []\n","    \n","    # Tokeniza todas as amostras de treinamento\n","    print('Tokenizando {:,} amostra...'.format(len(classes)))\n","    \n","    # Escolha o intervalo que o progresso será atualizado.\n","    intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(classes), numero_atualizacoes=10)\n","    \n","    # Para cada amostra de treinamento...\n","    for documento in documentos:\n","        \n","        # Relatório de progresso\n","        if ((len(input_ids_completos) % intervalo_atualizacao) == 0):\n","            print('  Tokenizado {:,} amostras.'.format(len(input_ids_completos)))\n","\n","        # Tokeniza a amostra.\n","        input_ids = tokenizer.encode(text=documento,                    # Documento a ser codificado.\n","                                    add_special_tokens=True,            # Adiciona os ttokens especiais.\n","                                    max_length=model_args.max_seq_len,  # Tamanho do truncamento!\n","                                    truncation=True,                    # Faz o truncamento!\n","                                    padding=False)                      # Não preenche.\n","                \n","        # Adicione o resultado tokenizado à nossa lista.\n","        input_ids_completos.append(input_ids)\n","        \n","    print('FEITO.')\n","    print('{:>10,} amostras\\n'.format(len(input_ids_completos)))\n","\n","    # =========================\n","    #      Seleciona os Lotes\n","    # =========================    \n","    \n","    # Classifique as duas listas pelo comprimento da sequência de entrada.\n","    amostras = sorted(zip(input_ids_completos, classes, documentoids), key=lambda x: len(x[0]))\n","\n","    print('{:>10,} amostras após classificação\\n'.format(len(amostras)))\n","\n","    import random\n","\n","    # Lista de lotes que iremos construir.\n","    batch_ordered_documentos = []\n","    batch_ordered_classes = []\n","    batch_ordered_documentoids = []\n","\n","    print('Criando lotes de tamanho {:}...'.format(batch_size))\n","\n","    # Escolha um intervalo no qual imprimir atualizações de progresso.\n","    intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(amostras), numero_atualizacoes=10)\n","        \n","    # Faça um loop em todas as amostras de entrada ... \n","    while len(amostras) > 0:\n","        \n","        # Mostra o progresso.\n","        if ((len(batch_ordered_documentos) % intervalo_atualizacao) == 0 \\\n","            and not len(batch_ordered_documentos) == 0):\n","            print('  Selecionado {:,} lotes.'.format(len(batch_ordered_documentos)))\n","        \n","        # `to_take` é o tamanho real do nosso lote. Será `batch_size` até\n","        # chegamos ao último lote, que pode ser menor.\n","        to_take = min(batch_size, len(amostras))\n","        \n","        # Escolha um índice aleatório na lista de amostras restantes para começar o nosso lote.\n","        select = random.randint(0, len(amostras) - to_take)\n","\n","        # Selecione um lote contíguo de amostras começando em `select`.\n","        #print (\"Selecionando lote de {:} a {:}\".format(select, select+to_take))\n","        batch = amostras[select:(select + to_take)]\n","\n","        #print(\"Tamanho do lote:\", len(batch))\n","        \n","        # Cada amostra é uma tupla --divida para criar uma lista separada de\n","        # sequências e uma lista de rótulos para este lote.\n","        batch_ordered_documentos.append([s[0] for s in batch])\n","        batch_ordered_classes.append([s[1] for s in batch])\n","        batch_ordered_documentoids.append([s[2] for s in batch])\n","        \n","        # Remova a amostra da lista\n","        del amostras[select:select + to_take]\n","\n","    print('\\n  FEITO - Selecionado {:,} lotes.\\n'.format(len(batch_ordered_documentos)))\n","\n","    # =========================\n","    #        Adicionando o preenchimento\n","    # =========================    \n","\n","    print('Preenchendo sequências dentro de cada lote...')\n","\n","    py_input_ids = []\n","    py_attention_masks = []\n","    py_labels = []\n","    list_documentoids = []\n","\n","    # Para cada lote...\n","    for (batch_input_ids, batch_labels, batch_documentoids) in zip(batch_ordered_documentos, batch_ordered_classes, batch_ordered_documentoids):\n","\n","        # Nova versão do lote, desta vez com sequências preenchidas e agora com\n","        # as máscaras de atenção definidas.\n","        batch_padded_input_ids = []\n","        batch_attention_masks = []\n","                \n","        # Primeiro, encontre a amostra mais longa do lote.\n","        # Observe que as sequências atualmente incluem os tokens especiais!\n","        max_size = max([len(input) for input in batch_input_ids])\n","        \n","        # Para cada entrada neste lote...\n","        for input in batch_input_ids:\n","                        \n","            # Quantos tokens pad precisam ser adicionados\n","            num_pads = max_size - len(input)\n","\n","            # Adiciona `num_pads` do pad token(tokenizer.pad_token_id) até o final da sequência.\n","            padded_input = input + [tokenizer.pad_token_id] * num_pads\n","\n","            # Define a máscara de atenção --é apenas um `1` para cada token real\n","            # e um `0` para cada token de preenchimento(pad).\n","            attention_mask = [1] * len(input) + [0] * num_pads\n","            \n","            # Adiciona o resultado preenchido ao lote.\n","            batch_padded_input_ids.append(padded_input)\n","            batch_attention_masks.append(attention_mask)\n","        \n","        # Nosso lote foi preenchido, portanto, precisamos salvar este lote atualizado.\n","        # Também precisamos que as entradas sejam tensores PyTorch, então faremos isso aqui.\n","        py_input_ids.append(torch.tensor(batch_padded_input_ids))\n","        py_attention_masks.append(torch.tensor(batch_attention_masks))\n","        py_labels.append(torch.tensor(batch_labels))\n","        list_documentoids.append(batch_documentoids)\n","    \n","    # Retorna o conjunto de dados em lotes inteligentes!\n","    return (py_input_ids, py_attention_masks, py_labels, list_documentoids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Thh-qfv5q4tI"},"source":["### Função de Treinamento"]},{"cell_type":"code","metadata":{"id":"ox8cl_CZDxc-"},"source":["# Import das bibliotecas\n","import random\n","import numpy as np\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaTreinamento(documentos_treino, classes_treino, documentoids_treino, EPOCAS = 4):\n","  \n","  print(\"\\nRealizando Treinamento \")\n","\n","  # Defina o valor da semente em todos os lugares para torná-lo reproduzível.\n","  seed_val = training_args.seed\n","\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  # Atualize todos os lotes ʻintervalo_atualizacao`.\n","  intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(documentos_treino), numero_atualizacoes=10)\n","\n","  # Medida do tempo total de treinamento.\n","  treinamento_t0 = time.time()\n","\n","  # Limpa o cache da GPU.\n","  torch.cuda.empty_cache()\n","\n","  # Coloque o modelo em modo de treinamento. \n","  model.train()\n","\n","  # Acumula as perdas do treinamento.\n","  train_losses = []\n","\n","  if model_args.use_wandb:\n","    # Log das métricas com wandb.\n","    wandb.watch(model)\n","\n","  # Barra de progresso da época.\n","  epoca_bar = tqdm_notebook(range(training_args.num_train_epochs), desc=f'Épocas', unit=f'épocas')\n","\n","  # Para cada época.\n","  for epoca_i in epoca_bar:\n","    \n","    # ========================================\n","    #               Treinamento\n","    # ========================================\n","    \n","    # Execute uma passada completa sobre o conjunto de treinamento.\n","\n","    # Recupera o lote inteligente\n","    (py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(model_args, tokenizer, documentos_treino, classes_treino, documentoids_treino, training_args.per_device_train_batch_size)\n","\n","    # Medida de quanto tempo leva o período de treinamento.\n","    treinamento_epoca_t0 = time.time()\n","\n","    # Acumula as perdas do treinamento da época.\n","    train_epoca_losses = []\n","\n","    # Barras de progresso.    \n","    lote_treino_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Epoca {epoca_i+1}', unit=f'lotes', total=len(py_input_ids) )\n","\n","    # Para cada lote dos dados de treinamento.\n","    for index in lote_treino_bar:      \n","\n","        # Progresso é atualizado a cada lotes, por exemplo, 100 lotes.\n","        if index % intervalo_atualizacao == 0 and not index == 0:            \n","            # Calcula gasto o tempo em minutos.\n","            tempoGasto = formataTempo(time.time() - treinamento_epoca_t0)\n","                        \n","            # Calcule o tempo restante com base em nosso progresso.\n","            passos_por_segundo = (time.time() - treinamento_epoca_t0) / index\n","            segundos_restantes = passos_por_segundo * (len(py_input_ids) - index)\n","            tempoRestante = formataTempo(segundos_restantes)\n","\n","            # Mostra o progresso.\n","            print('  Lote {:>7,}  de  {:>7,}.    Gasto: {:}.  Restante: {:}'.format(index, len(py_input_ids), tempoGasto, tempoRestante))\n","\n","        # Descompacte este lote de treinamento de nosso dataloader.\n","        #\n","        # À medida que descompactamos o lote, também copiaremos cada tensor para a GPU usando o\n","        # o método `to`\n","        #\n","        # `lote` é uma lista contém três tensores pytorch:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","\n","        # Recupera os tensores do lote e copia para a GPU usando o método `to` \n","        d_input_ids = py_input_ids[index].to(device)\n","        d_input_mask = py_attention_masks[index].to(device)\n","        d_labels = py_labels[index].to(device)     \n","        \n","        # Sempre limpe quaisquer gradientes calculados anteriormente antes de realizar um\n","        # passe para trás. PyTorch não faz isso automaticamente porque\n","        # acumular os gradientes é \"conveniente durante o treinamento de RNNs\".\n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()\n","\n","        # Execute um passe para frente (avalie o modelo neste lote de treinamento).\n","        # A documentação para esta função `model` está aqui:\n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # Ele retorna diferentes números de parâmetros dependendo de quais argumentos\n","        # são fornecidos e quais sinalizadores estão definidos. Para nosso uso aqui, ele retorna\n","        # a perda (porque fornecemos rótulos) e os \"logits\" - o modelo de saídas antes da ativação.     \n","\n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","        # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels))                  \n","        loss = outputs[0]\n","\n","        # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","        # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","        # A função `.detach().cpu()` retira da gpu.\n","        logits = outputs[1].detach().cpu()\n","  \n","        # Acumule a perda de treinamento em todos os lotes da época para que possamos\n","        # calcular a perda média no final da época. `loss` é um tensor contendo um único valor.   \n","        # A função '.cpu()' move loss para a cpu.\n","        # A função `.item ()` retorna apenas o valor Python do tensor.\n","        train_epoca_losses.append(loss.cpu().item())\n","        \n","        # Mostra a perda na barra de progresso.\n","        lote_treino_bar.set_postfix(loss=loss.cpu().item())\n","\n","        if model_args.use_wandb:\n","          wandb.log({\"train_batch_loss\": loss.cpu().item()})\n","\n","        # Execute uma passagem para trás para calcular os gradientes.\n","        # Todos os parâmetros do modelo deve ter sido setado para param.requires_grad = False\n","        loss.backward()            \n","\n","        # Corte a norma dos gradientes para 1.0.\n","        # Isso ajuda a evitar o problema de \"gradientes explosivos\".\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","       \n","        # Atualize os parâmetros e dê um passo usando o gradiente calculado.\n","        # O otimizador dita a \"regra de atualização\" - como os parâmetros são\n","        # modificados com base em seus gradientes, taxa de aprendizagem, etc.\n","        optimizer.step()\n","                           \n","        # Atualize a taxa de aprendizagem.\n","        scheduler.step()\n","\n","        del outputs\n","    \n","    # Média da perda do treinamento de todos os lotes da época.\n","    media_train_epoca_loss = np.mean(train_epoca_losses)\n","\n","    # Acumule a perda de treinamento de todas as épocas para calcular a perda média do treinamento.    \n","    train_losses.append(media_train_epoca_loss)\n","\n","    if model_args.use_wandb:\n","      wandb.log({\"media_train_epoca_loss\": media_train_epoca_loss})           \n","        \n","    # Medida de quanto tempo levou essa época.\n","    treinamento_epoca_total = formataTempo(time.time() - treinamento_epoca_t0)\n","\n","    print(\"  Média perda(loss) do treinamento da época : {0:.8f}\".format(media_train_epoca_loss))\n","    print(\"  Tempo de treinamento da época             : {:}\".format(treinamento_epoca_total))    \n","    print(\"  Tempo parcial do treinamento              : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_t0)))\n","\n","    del py_input_ids\n","    del py_attention_masks\n","    del py_labels\n","    del train_epoca_losses\n","    del lote_treino_bar\n","  \n","  # Média da perda do treinamento de todas as épocas.\n","  media_train_loss = np.mean(train_losses)\n","\n","  if model_args.use_wandb:\n","    wandb.log({\"media_train_loss\": media_train_loss})   \n","\n","  print(\"  Média perda(loss) treinamento : {0:.8f}\".format(media_train_loss))\n","\n","  del train_losses\n","  del epoca_bar\n","\n","  print(\"Treinamento completo!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ipCVZG0JqJr"},"source":["### Execução do Treinamento"]},{"cell_type":"markdown","metadata":{"id":"QdJEj_OoJqJr"},"source":["Estamos prontos para iniciar o treinamento!"]},{"cell_type":"code","metadata":{"id":"M5VCQ-psmtLR","colab":{"base_uri":"https://localhost:8080/","height":285,"referenced_widgets":["8bd516b3bc7a4c6887b3b207cbd65ea3","b47d5968ae7a4c6896385dde29ec0f0e","7f2917dbd6694ec989f80d29acdd1f3f","f495ba78db1f467d9adf5405f8761e12","4e0dce945cd0403aa3b1027348ccdc62","2462aadeceb3402cb4a7ef8c432cd086","14596a02a6a94df584b7f9b436b522e3","ad29b5452e3041289c3df77a24158304","8093b088d66c4c318e0809591f27c9de","63c73f6b99914e58918e2e57e23364e8","78db7cbe130140f697f0165624718fe8","54e74d94b5fe42609e8008436f08d744","4ce8506eba3b4720ad5de036ca05803c","6e5966dd1a1d45618b535627cd92b683","6c35130911fa49f98b459d114b26b3c5","867d6220a0a7435a9b82051b64d9422c"]},"executionInfo":{"status":"ok","timestamp":1626388609221,"user_tz":180,"elapsed":524510,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"7b7de253-0f79-4d8d-eaa9-5d4883267a41"},"source":["# Registra o tempo inicial.\n","treinamento_t0 = time.time()\n","\n","# Realiza o treinamento.\n","realizaTreinamento(documentos_treino, classes_treino, documentoids_treino, training_args.num_train_epochs)\n","  \n","# Medida de quanto tempo levou a execução do treinamento.\n","treinamento_total = formataTempo(time.time() - treinamento_t0)\n","\n","print(\"  Tempo total treinamento       : {:}\".format(treinamento_total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Realizando Treinamento \n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bd516b3bc7a4c6887b3b207cbd65ea3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Épocas', max=1.0, style=ProgressStyle(description_width='…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8093b088d66c4c318e0809591f27c9de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoca 1', max=2490.0, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["  Lote   1,000  de    2,490.    Gasto: 0:03:17.  Restante: 0:04:54\n","  Lote   2,000  de    2,490.    Gasto: 0:06:37.  Restante: 0:01:37\n","\n","  Média perda(loss) do treinamento da época : 0.31014063\n","  Tempo de treinamento da época             : 0:08:15\n","  Tempo parcial do treinamento              : 0:08:44 (h:mm:ss)\n","\n","  Média perda(loss) treinamento : 0.31014063\n","Treinamento completo!\n","  Tempo total treinamento       : 0:08:44\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"av-_hPByrUCA"},"source":["# 5 Avaliação\n","\n","Avaliando o modelo treinado no conjunto de dados de teste."]},{"cell_type":"markdown","metadata":{"id":"teXptLZNjszT"},"source":["## 5.1 Função de Avaliação"]},{"cell_type":"code","metadata":{"id":"R8DIJXnmjw5v"},"source":["# Import das bibliotecas.\n","import torch\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaAvaliacao(documentos_teste, classes_teste, documentoids_teste):\n","\n","  # Armazena o resultado da avaliação executada\n","  lista_resultado_avaliacao = []\n","\n","  print(\"\\nRealizando Avaliação: {}\")\n","\n","  # Predição no conjunto de teste no modelo.\n","  print('Predizendo rótulos para {:,} documentos de teste...'.format(len(documentos_teste)))\n","\n","  # Use nossa nova função para preparar completamente nosso conjunto de dados.\n","  (py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(model_args, tokenizer, documentos_teste, classes_teste, documentoids_teste, training_args.per_device_eval_batch_size)\n","  \n","  # Escolha um intervalo para imprimir atualizações de progresso.\n","  intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(py_input_ids), numero_atualizacoes=10)\n","\n","  # Coloque o modelo em modo de avaliação.\n","  model.eval()\n","\n","  # Acumula as perdas da avaliação.\n","  test_losses = []\n","\n","  # Acumula os resultados dos testes.\n","  vp = [] # Verdadeiro positivo\n","  vn = [] # Verdadeiro negativo\n","  fp = [] # Falso positivo\n","  fn = [] # Falso negativo\n","\n","  # Barra de progresso dos lotes de teste.\n","  lote_teste_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Lotes ', unit=f'lotes', total=len(py_input_ids))\n","\n","  # Para cada lote dos dados de avaliação(teste).\n","  for index in lote_teste_bar:\n","\n","    # Progresso é atualizado a cada lotes, por exemplo, 100 lotes.\n","    if index % intervalo_atualizacao == 0 and not index == 0:        \n","        # Calcula o tempo gasto em minutos.\n","        tempoGasto = formataTempo(time.time() - avaliacao_t0)\n","        \n","        # Calculate the time tempoRestante based on our progress.\n","        passos_por_segundo = (time.time() - avaliacao_t0) / index\n","        segundos_restantes = passos_por_segundo * (len(py_input_ids) - index)\n","        tempoRestante = formataTempo(segundos_restantes)\n","\n","        # Mostra o progresso.\n","        print('  Lote {:>7,}  de  {:>7,}.    Gasto: {:}.  Restando: {:}'.format(index, len(py_input_ids), tempoGasto, tempoRestante))\n","    \n","    # Copia o lote para a GPU.\n","    d_input_ids = py_input_ids[index].to(device)\n","    d_input_mask = py_attention_masks[index].to(device)\n","    d_labels = py_labels[index].to(device)\n","    d_documentoids = documentoids[index]\n","\n","    # Diga a pytorch para não se preocupar em construir o gráfico de computação durante\n","    # o passe para frente, já que isso só é necessário para backprop (treinamento).\n","    with torch.no_grad():\n","        # Obtenha a saída de \"logits\" pelo modelo. Os \"logits\" são a saída\n","        # valores antes de aplicar uma função de ativação como o softmax.        \n","        # Retorno de model quando ´last_hidden_state=True´ é setado:    \n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids,\n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","    # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels). \n","    # É útil para comparar com a perda do treinamento, quando é realizado a avaliação entre as épocas de treinamento.\n","    loss = outputs[0]\n","\n","    # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","    # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição\n","    logits = outputs[1]\n","        \n","    # Acumule a perda da avaliação em todos os lotes para que possamos\n","    # calcular a perda média no final. `loss` é um tensor contendo um único valor.\n","    # A função '.cpu()' move loss para a cpu.\n","    # A função `.item ()` retorna apenas o valor Python do tensor.\n","    test_losses.append(loss.cpu().item())\n","\n","    # Recupera o indice do melhor resultado, maior valor dos tensores para coluna(1)\n","    _, classificacao = torch.max(logits, 1)\n","\n","    # Verifica a classificação realizada e o rótulo previsto\n","    vp.append(((classificacao==1) & (d_labels==1)).sum().cpu().item())\n","    vn.append(((classificacao==0) & (d_labels==0)).sum().cpu().item())\n","    fp.append(((classificacao==1) & (d_labels==0)).sum().cpu().item())\n","    fn.append(((classificacao==0) & (d_labels==1)).sum().cpu().item())\n","\n","    # Adiciona o documento de teste, o rótulo e a classificação realizada a lista de resultado\n","    for lote in range(len(d_labels)):\n","                \n","        lista_resultado_avaliacao.append([d_documentoids[lote],\n","                                d_labels[lote].cpu().item(), \n","                                classificacao[lote].cpu().item()])\n","      \n","    del outputs\n","\n","  # Soma as classificações realizadas\n","  vp_s, vn_s, fp_s, fn_s = sum(vp), sum(vn), sum(fp), sum(fn)\n","\n","  # Acurácia indica uma performance geral do modelo. \n","  # Dentre todas as classificações, quantas o modelo classificou corretamente(vp=1 e vn=0).\n","  acc = (vp_s+vn_s)/(vp_s+vn_s+fp_s+fn_s)\n","\n","  # Recall(Revocação) avalia todas as situações da classe Positivo(vp=1) com o valor esperado e quantas estão corretas;\n","  if (vp_s+fn_s) != 0:\n","      rec = (vp_s)/(vp_s+fn_s)\n","  else:\n","      rec = 0\n","\n","  # Precisão avalia as classificações da classe positivo(vp=1 e fp=0) que o modelo fez e quantas estão corretas.\n","  if (vp_s+fp_s) != 0:\n","      pre = (vp_s)/(vp_s+fp_s)\n","  else:\n","      pre = 0  \n","\n","  # F1 é a média harmônica entre precisão e recall.\n","  if (pre + rec) != 0:  \n","    f1 = 2 * ((pre * rec)/(pre + rec))\n","  else:\n","    f1 = 0\n","  \n","  # Média da perda da avaliação\n","  media_test_loss = np.mean(test_losses)\n","\n","  if model_args.use_wandb:\n","    # Log do wandb\n","    wandb.log({\"acuracia\": acc})\n","    wandb.log({\"vp\": vp_s})\n","    wandb.log({\"vn\": vn_s})\n","    wandb.log({\"fp\": fp_s})\n","    wandb.log({\"fn\": fn_s})\n","    wandb.log({\"media_test_loss\": media_test_loss})\n","\n","\n","\n","  del py_input_ids\n","  del py_attention_masks\n","  del py_labels\n","  del test_losses\n","  del lote_teste_bar\n","\n","  return media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8m9VFDtWhRxN"},"source":["## 5.2 Execução da Avaliação"]},{"cell_type":"code","metadata":{"id":"9y7MBzY_j_uF","colab":{"base_uri":"https://localhost:8080/","height":341,"referenced_widgets":["3b4b4d435379436db5101fadd639f69e","b125c21282db47869fc57b1206507660","72a595c1b108413194eff8ffefe00391","0291ac0f874f46f39d0e2b8afa96209a","2e9f277e9fd24496b65405ab25794139","1fa151958c1941f5bd2ff2207b66c853","df844f770583461581032a21eb1370cf","0cbda363d70047a598ad6bfef0c23a41"]},"executionInfo":{"status":"ok","timestamp":1626388813410,"user_tz":180,"elapsed":204197,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"a436974d-59df-42fe-bd8e-99b86a6318ff"},"source":["# Registra o tempo inicial.\n","avaliacao_t0 = time.time()\n","\n","# Realiza a avaliação do modelo.\n","media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(documentos_teste, classes_teste, documentoids_teste)\n","\n","print('Avaliação loss           : {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}'.format( \n","        media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))      \n","\n","print(\"Acurácia                 : {:.8f}\".format(acc))  \n","\n","# Medida de quanto tempo levou a execução do treinamento e avaliação\n","avaliacao_total = formataTempo(time.time() - avaliacao_t0)\n","\n","print(\"Tempo gasto na avaliação : {:}\".format(avaliacao_total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Realizando Avaliação: {}\n","Predizendo rótulos para 22,440 documentos de teste...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b4b4d435379436db5101fadd639f69e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Lotes ', max=2805.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["  Lote     300  de    2,805.    Gasto: 0:00:52.  Restando: 0:07:10\n","  Lote     600  de    2,805.    Gasto: 0:01:11.  Restando: 0:04:21\n","  Lote     900  de    2,805.    Gasto: 0:01:31.  Restando: 0:03:12\n","  Lote   1,200  de    2,805.    Gasto: 0:01:48.  Restando: 0:02:25\n","  Lote   1,500  de    2,805.    Gasto: 0:02:05.  Restando: 0:01:49\n","  Lote   1,800  de    2,805.    Gasto: 0:02:23.  Restando: 0:01:20\n","  Lote   2,100  de    2,805.    Gasto: 0:02:41.  Restando: 0:00:54\n","  Lote   2,400  de    2,805.    Gasto: 0:02:59.  Restando: 0:00:30\n","  Lote   2,700  de    2,805.    Gasto: 0:03:17.  Restando: 0:00:08\n","\n","Avaliação loss           : 1.20907344; Acc: 0.75392157; Rec: 0.65775401; Pre: 0.81438976, F1:0.72773888, vp: 7380; vn: 9538; fp: 1682; fn: 3840\n","Acurácia                 : 0.75392157\n","Tempo gasto na avaliação : 0:03:24\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DloA0HIShFzW"},"source":["## 5.3 Salvando o resultado da classificação"]},{"cell_type":"code","metadata":{"id":"Is6qvwwh-nJW"},"source":["def salvaResultadoClassificacao(lista_resultado_avaliacao):\n","\n","  if model_args.salvar_classificacao:\n","\n","    # Import das bibliotecas.\n","    import os\n","    import datetime\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_CLASSIFICACAO = training_args.output_dir + MODELO_BERT + TAMANHO_BERT\n","\n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_CLASSIFICACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/holdout/Classificacao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_CLASSIFICACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_CLASSIFICACAO)\n","      print('Diretório criado: {}'.format(DIRETORIO_CLASSIFICACAO))\n","    else:\n","      print('Diretório já existe: {}'.format(DIRETORIO_CLASSIFICACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_CLASSIFICACAO_COMPLETO = DIRETORIO_CLASSIFICACAO + NOME_ARQUIVO_CLASSIFICACAO + \".csv\"\n","\n","    # Gera todo o conteúdo a ser salvo no arquivo\n","    novoConteudo = \"\"        \n","    for resultado in lista_resultado_avaliacao:      \n","      novoConteudo = novoConteudo + data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\" + str(resultado[0]) + \";\" + str(resultado[1]) + \";\" + str(resultado[2]) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO):\n","      print(\"Atualizando arquivo classificação: {}\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novoConteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","    else:\n","      print(\"Criando arquivo classificação: {}\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      arquivo.writelines('data;id;classe;predicao\\n' + novoConteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnu6iKHwAaTb"},"source":["salvaResultadoClassificacao(lista_resultado_avaliacao)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_otFoSBYBBTD"},"source":["## 5.4 Salvando o resultado da avaliação"]},{"cell_type":"markdown","metadata":{"id":"PUjV5m1X_TYH"},"source":["### Salva o resultado da avaliação \n","\n","Salva o resultado da avaliação do conjunto de dados de teste."]},{"cell_type":"code","metadata":{"id":"Oa_cUt7f-9Gb"},"source":["def salvaResultadoAvaliacao():\n","\n","  if model_args.salvar_avaliacao:\n","\n","    # Import das bibliotecas.\n","    import os\n","    import datetime\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_AVALIACAO = training_args.output_dir + MODELO_BERT + TAMANHO_BERT\n","\n","    # Diretório para salvar o arquivo de resultado.\n","    DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/holdout/Avaliacao/\"\n","  \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_AVALIACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_AVALIACAO)\n","      print('Diretório criado: {}'.format(DIRETORIO_AVALIACAO))\n","    else:\n","      print('Diretório já existe: {}'.format(DIRETORIO_AVALIACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + \".csv\"\n","\n","    # Conteúdo a ser adicionado.\n","    novoConteudo = NOME_ARQUIVO_AVALIACAO + \";\" + data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\"  + treinamento_total + \";\"  + str(acc) + \";\"  +  str(vp_s) + \";\"  +  str(vn_s) + \";\" +  str(fp_s) + \";\" +  str(fn_s) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      print(\"Atualizando arquivo resultado avaliação: {}\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novoConteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","    else:\n","      print(\"Criando arquivo resultado avaliação: {}\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      arquivo.writelines('arquivo;data;tempo;acuracia;vp;vn;fp;fn\\n' + novoConteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aiVdm7P_TlV"},"source":["salvaResultadoAvaliacao()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bUskOwzJmpDB"},"source":["### Carrega e calcula a média da acurácia das execuções\n"]},{"cell_type":"code","metadata":{"id":"n-f9-4lCmpDB"},"source":["def carregaResultadoAvaliacao():\n","\n","  # Import das bibliotecas.\n","  import os\n","  import pandas as pd\n","\n","  # Acumuladores.\n","  somaAcuracia = 0\n","  listaTempo = []\n","  contaExecucoes = 0\n","\n","  # Nome arquivo resultado\n","  NOME_ARQUIVO_AVALIACAO = training_args.output_dir + MODELO_BERT + TAMANHO_BERT\n","\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/holdout/Avaliacao/\"\n","\n","  # Verifica se o diretório dos resultados existem.\n","  if os.path.exists(DIRETORIO_AVALIACAO):\n","    # Nome do arquivo mais o caminho\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + \".csv\"\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      # Carrega os dados do arquivo  \n","      dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","\n","      # Mostra os dados do teste da execução.\n","      for index, linha in dados.iterrows():\n","        \n","          # Cálculo das estatísticas\n","          acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])\n","          if (linha['vp']+linha['fn']) != 0:\n","              rec = (linha['vp'])/(linha['vp']+linha['fn'])\n","          else:\n","              rec = 0\n","          if (linha['vp']+linha['fp']) != 0:\n","              pre = (linha['vp'])/(linha['vp']+linha['fp'])\n","          else:  \n","              pre = 0\n","          if (pre + rec) != 0:  \n","              f1 = 2 * ((pre * rec)/(pre + rec))\n","          else:\n","              f1 = 0\n","          qtdeTestes = linha['vp']+linha['vn']+linha['fp']+linha['fn']\n","          print('Arquivo: {}, Data: {}, Tempo:{}, QtdeTeste: {:3d}, Acc: {:.8f}, Rec: {:.8f}, Pre: {:.8f}, F1:{:.8f}, vp: {:4d}; vn: {:4d}; fp: {:4d}; fn: {:4d}'.format(\n","              linha['arquivo'], linha['data'], linha['tempo'], qtdeTestes, acc, rec, pre, f1, linha['vp'], linha['vn'], linha['fp'], linha['fn']))  \n","           \n","          # Guarda o tempo.\n","          listaTempo.append(str(linha['tempo']))\n","\n","          # Procura a maior acurácia.\n","          somaAcuracia = somaAcuracia + acc\n","\n","          # Conta o número de execuções.\n","          contaExecucoes = contaExecucoes + 1\n","\n","      # Mostra a soma da acurácia . \n","      print('Total acurácia                                          : {:.8f}'.format(somaAcuracia))\n","      # Mostra a quantidade de exeucões.\n","      print('Quantidade de execuções                                 : {}'.format(contaExecucoes))  \n","      # Calcula a média.\n","      media = somaAcuracia/contaExecucoes\n","      print('A média da acurácia de {:2d} execuções é                   : {:.8f}'.format(contaExecucoes, media))\n","      print('O tempo gasto na execução do treinamento {:2d} execuções é : {}'.format(contaExecucoes, somaTempo(listaTempo)))\n","      print('A média de tempo de {:2d} execuções é                      : {}'.format(contaExecucoes, mediaTempo(listaTempo)))\n","    else:\n","      print('Arquivo com os resultados não encontrado')    \n","  else:\n","    print('Diretório com os resultados não encontrado')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITvioKti_sFq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388814354,"user_tz":180,"elapsed":959,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e15190b6-a009-487f-f38f-f6b31f6cf512"},"source":["carregaResultadoAvaliacao()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Arquivo com os resultados não encontrado\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Q_zqfWmlIjMc"},"source":["## 6.1 Salvando o Modelo para o wandb"]},{"cell_type":"code","metadata":{"id":"nxLQm2CR-F3m"},"source":["def salvaModeloWandb():\n","  \n","  if model_args.use_wandb and model_args.salvar_modelo_wandb:\n","  \n","    # Salva o modelo para o wandb    \n","    torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model_dict.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9U-parMIj00"},"source":["salvaModeloWandb()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2ZttMYBJqJu"},"source":["## 6.2 Salvando o Modelo Ajustado\n","\n","Esta primeira célula (obtida de `run_glue.py` [aqui](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) grava o modelo e o tokenizador no disco."]},{"cell_type":"code","metadata":{"id":"2MDXCrgPJqJu"},"source":["def salvaModelo():\n","  \n","  if model_args.salvar_modelo:\n","  \n","    # Import de bibliotecas.\n","    import os\n","\n","    # Salvando as melhores práticas: se você usar nomes padrão para o modelo, você pode recarregá-lo usando from_pretrained ()\n","\n","    # Diretório de salvamento do modelo.\n","    output_dir = '/content/model_save/'\n","\n","    # Cria o diretório de saída se necessário.\n","    if not os.path.exists(output_dir):\n","      os.makedirs(output_dir)\n","\n","    print('Salvando o modelo para {}'.format(output_dir))\n","\n","    # Salve um modelo treinado, configuração e tokenizer usando `save_pretrained ()`.\n","    # Eles podem então ser recarregados usando `from_pretrained ()`.\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Cuide do treinamento distribuído/paralelo\n","    model_to_save.save_pretrained(output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","\n","    # Boa prática: salve seus argumentos de treinamento junto com o modelo treinado.\n","    torch.save (mode_args, os.path.join (output_dir, 'mode_args.bin'))\n","    torch.save (training_args, os.path.join (output_dir, 'training_args.bin'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ee0YY2PV-Xj7"},"source":["salvaModelo()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r44zwUNFJqJu"},"source":["Vamos verificar os tamanhos dos arquivos, por curiosidade."]},{"cell_type":"code","metadata":{"id":"t60NUZueJqJv"},"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=K /content/model_save/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sTnm92AaJqJv"},"source":["O maior arquivo é o peso do modelo, em torno de 416MB o base e 1.25G o large."]},{"cell_type":"code","metadata":{"id":"Nzl0zScjJqJv"},"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=M /content/model_save/pytorch_model.bin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OstCHN_JqJv"},"source":["Para salvar seu modelo nas sessões do Colab Notebook, faça o download no seu computador local ou, idealmente, copie-o no seu Google Drive."]},{"cell_type":"code","metadata":{"id":"s19-WOYdJqJv"},"source":["if model_args.salvar_modelo:\n","\n","  # Importando as bibliotecas.\n","  import os\n","  \n","  # Diretório local de salvamento do modelo.\n","  DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/'\n","\n","  # Diretório remoto de salvamento do modelo.  \n","  DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/holdout/modelo/modelo\" + MODELO_BERT + TAMANHO_BERT\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_REMOTO_MODELO_AJUSTADO):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_REMOTO_MODELO_AJUSTADO)\n","    print('Diretório criado: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","  else:\n","    print('Diretório já existe: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","\n","  ## Copia o arquivo do modelo para o diretório no Google Drive.\n","  !cp -r '$DIRETORIO_LOCAL_MODELO_AJUSTADO'* '$DIRETORIO_REMOTO_MODELO_AJUSTADO'\n","\n","  print(\"Modelo copiado!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.3 Tempo final de processamento\n","\n","Tempo processamento:  1:34:52 (h:mm:ss)"]},{"cell_type":"code","metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626388815281,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"dbf86719-5bc6-4435-ab12-a854e4917789"},"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","finalProcessamento = time.time()\n","tempoTotalProcessamento = formataTempo(finalProcessamento - inicioProcessamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempoTotalProcessamento))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  Tempo processamento:  0:15:33 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rD9sTJHMp5Go"},"source":["Executa o wandb para finalizar a execução anterior"]},{"cell_type":"code","metadata":{"id":"BMRLEXzfp5Q8"},"source":["if model_args.use_wandb:\n","  \n","    # Importando a biblioteca\n","    import wandb\n","\n","    # Inicializando o registro do experimento\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_avaliacaomoodle_v1_c_sb\", name=training_args.output_dir)"],"execution_count":null,"outputs":[]}]}