{"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["#Ajuste fino do conjunto de dados CSTNews usando BERT Transformers by HuggingFace e Lotes Inteligentes e Validação Cruzada para todos os Folds\n","\n","Com base no modelo BERT pré-treinado realiza o ajuste fino para os dados CSTNews para classificar documentos coerentes e incoerentes.\n","\n","- Realiza o ajuste fino nos dados de CSTNEWS de Márcio Dias.\n","- Realiza a avaliação do conjunto de teste para um determinado fold(10%).\n","- A seção 2 - parametrização define os argumentos da execução.\n","\n","Notebook base: https://colab.research.google.com/drive/1KDeFAHvRFq3bY5onzj8Wgul3rRcrQNaC?usp=sharing\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n","\n","**Artigo padding dinâmico:**\n","https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e"]},{"cell_type":"markdown","metadata":{"id":"xyxb5Px3p1-e"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do notebook."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1626432351071,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"LOHCMMDsiyZg"},"outputs":[],"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicioProcessamento = time.time()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1626432351072,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"v2ROFCsyHu8B","outputId":"d70c924d-45b4-44a0-bc2d-7e0039f584b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Tempo de início de processamento:  1626432350.6134887 (h:mm:ss)\n"]}],"source":["print(\"  Tempo de início de processamento:  {:} (h:mm:ss)\".format(inicioProcessamento))"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.2 Tratamento de logs"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1626432351073,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"DcopxbGZqDip"},"outputs":[],"source":["# Biblioteca de logging\n","import logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.3 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1626432351073,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","import sys\n","\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = 'google.colab' in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"rceIwWa7UmFZ"},"source":["## 1.4 Biblioteca de limpeza de tela"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1626432351074,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"PXTEvmuhUmjO"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"LJzK1XjCnZak"},"source":["## 1.5 Conecta ao Google Drive\n","\n","É necessário existir a pasta '/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/Resultados/' para receber os resutlados do notebook."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19732,"status":"ok","timestamp":1626432370788,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"Dz3RRgR-nZan","outputId":"fdf93cc9-e252-4bca-b677-00dc136b85d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Monta o Google Drive para esta instância de notebook.\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.6 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10377,"status":"ok","timestamp":1626432381162,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"ejzpgGrFM0-j","outputId":"9248ece1-bc58-49d1-d52d-eb1ce7c36f8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/eb/cb124dd42e205a2d5fd832add322292a731580acb5bce3a0daf423de5f02/wandb-0.11.0-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 4.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting subprocess32\u003e=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 8.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil\u003e=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Collecting GitPython\u003e=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n","\u001b[K     |████████████████████████████████| 174kB 23.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting urllib3\u003e=1.26.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl (138kB)\n","\u001b[K     |████████████████████████████████| 143kB 24.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting sentry-sdk\u003e=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/75fad31fff378871c462745ce724b3701a6acad17028d79476ec2545e40f/sentry_sdk-1.3.0-py2.py3-none-any.whl (133kB)\n","\u001b[K     |████████████████████████████████| 143kB 20.6MB/s \n","\u001b[?25hCollecting configparser\u003e=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied, skipping upgrade: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied, skipping upgrade: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting docker-pycreds\u003e=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions\u003e=3.7.4.0; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (3.7.4.3)\n","Collecting smmap\u003c5,\u003e=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=40053476cf08464a5e884d1b90714827f1b51da1ab3d49a35b2f50a3d4b23214\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=a1e560b6a602a3d93d64a6d5f29e02a4742446b706a75305677904f5675dd764\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 pathtools\n","\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: subprocess32, smmap, gitdb, GitPython, pathtools, urllib3, sentry-sdk, configparser, shortuuid, docker-pycreds, wandb\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 urllib3-1.26.6 wandb-0.11.0\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.7 Instalação BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6444,"status":"ok","timestamp":1626432387597,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"1RfUN_KolV-f","outputId":"23e329d4-f34f-4fa1-d9e5-8aa73c324062"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 5.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.0.12)\n","Requirement already satisfied, skipping upgrade: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.41.1)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 27.7MB/s \n","\u001b[?25hCollecting tokenizers\u003c0.11,\u003e=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 18.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.6.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.5.1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.5.1) (7.1.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.5.1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions\u003e=3.6.4; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers==4.5.1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers==4.5.1) (3.5.0)\n","Requirement already satisfied, skipping upgrade: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers==4.5.1) (2.4.7)\n","Requirement already satisfied, skipping upgrade: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.5.1) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 44.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.5.1) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.5.1) (3.0.4)\n","\u001b[31mERROR: wandb 0.11.0 has requirement urllib3\u003e=1.26.5, but you'll have urllib3 1.25.11 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: sacremoses, tokenizers, transformers, urllib3\n","  Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.5.1 urllib3-1.25.11\n"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"Ne84ggOIwvlN"},"source":["## 1.8 Recupera o coebert do Github"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4739,"status":"ok","timestamp":1626432392326,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"_HasDDV1Il1t","outputId":"492304cc-a6c8-4576-bc8f-1ab8ae51838f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'coebert_v1'...\n","remote: Enumerating objects: 2932, done.\u001b[K\n","remote: Counting objects: 100% (1039/1039), done.\u001b[K\n","remote: Compressing objects: 100% (575/575), done.\u001b[K\n","remote: Total 2932 (delta 504), reused 875 (delta 404), pack-reused 1893\u001b[K\n","Receiving objects: 100% (2932/2932), 23.07 MiB | 15.02 MiB/s, done.\n","Resolving deltas: 100% (1755/1755), done.\n"]}],"source":["tokengit = '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'\n","nomeusuario = 'osmarbraz'\n","repositorio = 'coebert_v1.git'\n","!git clone https://{tokengit}@github.com/{nomeusuario}/{repositorio}"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1626432392327,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"ZYrhaS9zaWmp"},"outputs":[],"source":["#Muda o diretório corrente para a pasta clonada\n","import sys\n","sys.path.append('./coebert_v1/coebert')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1626432392328,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"M3MgI7Ldb9ce"},"outputs":[],"source":["# Import de bibliotecas\n","from util.utilmodulo import *\n","from util.utiltempo import *\n","from util.utilarquivo import *"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.9 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -\u003e Notebook Settings -\u003e Hardware accelerator -\u003e (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1720,"status":"ok","timestamp":1626432394032,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"vtaYZmc3Vbfj","outputId":"b8670a65-ab0d-48ce-c4fd-a98536464a36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dispositivo GPU não encontrado\n"]}],"source":["# Importando a biblioteca\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == '/device:GPU:0':\n","    print('Encontrei GPU em: {}'.format(device_name))\n","else:\n","    print('Dispositivo GPU não encontrado')\n","    #raise SystemError('Dispositivo GPU não encontrado')"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla V100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla V100-SXM2-16GB(Pro)\n","- 2o Tesla P100-PCIE-16GB\n","- 3o Tesla T4\n","- 4o Tesla P4 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)\n","- 5o Tesla K80 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4659,"status":"ok","timestamp":1626432398689,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"zrjqDO6nWa8J","outputId":"4b910756-6443-49fd-89c0-eb123ec3521e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sem GPU disponível, usando CPU.\n"]}],"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1626432398690,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"1iC5-pSAVh7_","outputId":"d86e1056-d48b-40a4-8661-11dbc5ebed2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução\u003e \"Alterar tipo de tempo de execução\"\n","e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","print('Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n'.format(ram_gb))\n","\n","if ram_gb \u003c 20:\n","  print('Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução\u003e \"Alterar tipo de tempo de execução\"')\n","  print('e selecione High-RAM. Então, execute novamente está célula')\n","else:\n","  print('Você está usando um ambiente de execução de memória RAM alta!')"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1626432398690,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Importando as bibliotecas.\n","from transformers import TrainingArguments\n","\n","# Definição dos parâmetros de Treinamento.\n","training_args = TrainingArguments(\n","    # AjusteFinoCSTNews_v1_C_SB_KF = nome do notebook\n","    # E = número de épocas\n","    # lr = taxa de aprendizagem\n","    # b = lotes de treino e avaliação\n","    # f = número do fold\n","    output_dir = 'AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f',    \n","    save_steps = 0,    \n","    seed = 42,\n","    num_train_epochs = 1, # Intervalo de valores: 2, 3, 4\n","    learning_rate = 5e-5, # Intervalo de valores: 1e-5, 2e-5, 3e-5, 4e-5, 5e-5 \n","    gradient_accumulation_steps = 1,\n","    per_device_train_batch_size = 4, \n","    per_device_eval_batch_size = 8,        \n","    evaluation_strategy = 'epoch'\n",")\n","\n","# Import de bibliotecas\n","from bert.bertarguments import ModeloArgumentosClassificacao\n","\n","# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosClassificacao(     \n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",    \n","    #pretrained_model_name_or_path = 'bert-base-multilingual-cased',\n","    do_lower_case = False,   # default True\n","    num_labels = 2,\n","    output_attentions = False,    # default False\n","    output_hidden_states = False, # default False \n","    optimizer = 'AdamW',\n","    use_wandb = False,\n","    salvar_modelo_wandb = False,\n","    salvar_modelo = False,\n","    salvar_avaliacao = False, # Salva o resultado classificações\n","    salvar_classificacao = False, # Salva o resultado da avaliação das classificações\n","    fold = 1 # Intervalo de valores: 1 a 10, É utilizado somente para logs. Use as variáveis das últimas linhas de bloco para definir um intervalo.\n",")\n","\n","# Determina o intervalo de folds a ser avaliado\n","inicioFold = 1\n","fimFold = 10"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1626432398690,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"he244EnGnqT4"},"outputs":[],"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT =  getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"8cC_PRoPRl7w"},"source":["# 3 BERT"]},{"cell_type":"markdown","metadata":{"id":"e2Slpfk-dIUw"},"source":["## Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **'neuralmind/bert-base-portuguese-cased'**\n","* **'neuralmind/bert-large-portuguese-cased'**"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1626432398691,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"04TdVv56TB73"},"outputs":[],"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","# Carrega o modelo e tokenizador do BERT\n","# model, tokenizer = carregaBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"wJdbTzeejhOE"},"source":["# 4 Treino"]},{"cell_type":"markdown","metadata":{"id":"IrKMXRNm7OI6"},"source":["## 4.1 Wandb\n","\n","https://wandb.ai/osmar-braz/ajustefinocstnews_v1_c_sb_kfold/table?workspace=user-osmar-braz\n"]},{"cell_type":"markdown","metadata":{"id":"ezk8hklEvPYq"},"source":["### Função de inicialização wandb"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1626432398691,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"rdsn_fhsvPwO"},"outputs":[],"source":["def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    # Importando a biblioteca.\n","    import wandb\n","\n","    #Login via linha de comando\n","    !wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd\n","\n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_v1_c_sb_kfold\", name=training_args.output_dir + str(model_args.fold))\n","\n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","    # Atualiza os parâmetros de treinamento no wandb.\n","    wandb.config.update(training_args)\n","\n","    # Registra os parämetros não literais do model_args.\n","    wandb.log({\"max_seq_len\": model_args.max_seq_len})\n","    wandb.log({\"do_lower_case\": model_args.do_lower_case})\n","    wandb.log({\"output_hidden_states\": model_args.output_hidden_states})    \n","    wandb.log({\"fold\": model_args.fold})\n","\n","    return wandb"]},{"cell_type":"markdown","metadata":{"id":"nJzDVmgts4nd"},"source":["## 4.2 Colab GPU\n","\n","Conecta o modelo carregado do BERT a GPU para reduzir o tempo de processamento."]},{"cell_type":"markdown","metadata":{"id":"5YRD8msZyLWh"},"source":["### Função conecta GPU"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1626432398692,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"3x2zp5UnCN4E"},"outputs":[],"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n"]},{"cell_type":"markdown","metadata":{"id":"xI3kvpJaFqYq"},"source":["## 4.3 Arquivo dos dados\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4y2EOkgR0dBD"},"source":["### Função de download dos arquivos de dados"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1626432398692,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"brUDPsSC0gPJ"},"outputs":[],"source":["def downloadArquivoDados1():\n","\n","  # Cria o diretório para receber os arquivos de dados\n","\n","  # Import das bibliotecas.\n","  import os\n","\n","  # Diretório dos arquivos de dados.\n","  DIRETORIO = \"/content/validacao_kfold\"\n","\n","  # Apaga o diretório e seus arquivos.\n","  !rm -rf \"$DIRETORIO\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO)\n","    print('Diretório criado: {}'.format(DIRETORIO))\n","  else:\n","    print('Diretório já existe: {}'.format(DIRETORIO))\n","\n","  # Download do arquivo de dados\n","  \n","  # Nome do arquivo a ser criado.\n","  NOME_ARQUIVO = 'CSTNEWS_MD_KFOLD_10.zip'\n","\n","  # Apaga o arquivo.\n","  !rm $NOME_ARQUIVO\n","\n","  # Realiza o download do arquivo da url especificada                       \n","  !wget -O $NOME_ARQUIVO  https://github.com/osmarbraz/coebert/blob/main/conjuntodedado/$NOME_ARQUIVO?raw=true\n","\n","  # Descompactando os arquivos\n","  # Lista o diretório corrente e os arquivos.\n","  !pwd\n","  !ls -la\n","\n","  # Descompacta o arquivo.\n","  !unzip -o $NOME_ARQUIVO -d $DIRETORIO\n","\n","  # Lista os arquivos do diretório corrente.\n","  !ls -la  "]},{"cell_type":"markdown","metadata":{"id":"ql6f11tI1OqZ"},"source":["### Download do arquivo de dados"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1626432398692,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"0JJqPd441O3i"},"outputs":[],"source":["#downloadArquivoDados()"]},{"cell_type":"markdown","metadata":{"id":"5EbwyBfvHrbj"},"source":["### Carregando os dados do fold"]},{"cell_type":"markdown","metadata":{"id":"cKaU03Si1U4E"},"source":["### Função de carregamento dos dados de um fold"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1626432398693,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"DrtbjCZb1ZMY"},"outputs":[],"source":["def carregamentoDadosFold1(fold):\n","\n","  # Import das bibliotecas.\n","  import pandas as pd\n","\n","  # Diretório dos arquivos de dados.\n","  DIRETORIO = \"/content/validacao_kfold\"\n","\n","  # Define o prefixo do nome dos arquivos dos folds\n","  PREFIXO_NOME_ARQUIVO_TREINO = \"cstnews_md_train_f\"\n","  PREFIXO_NOME_ARQUIVO_TESTE = \"cstnews_md_test_f\"\n","\n","  # Nome dos arquivos.\n","  ARQUIVO_TREINO = DIRETORIO + \"/\" + PREFIXO_NOME_ARQUIVO_TREINO + str(fold) + \".csv\"\n","  ARQUIVO_TESTE = DIRETORIO + \"/\" + PREFIXO_NOME_ARQUIVO_TESTE + str(fold) + \".csv\" \n","\n","  print(\"Carregando arquivo de treino: {}\".format(ARQUIVO_TREINO))\n","  print(\"Carregando arquivo de teste: {}\".format(ARQUIVO_TESTE))\n","\n","  # Carrega o dataset de treino e teste.\n","  dfdados_train = pd.read_csv(ARQUIVO_TREINO, sep=';')\n","  print('Qtde de dados de treino: {}'.format(len(dfdados_train)))\n","  dfdados_test = pd.read_csv(ARQUIVO_TESTE, sep=';')\n","  print('Qtde de dados de teste: {}'.format(len(dfdados_test)))\n","\n","  return dfdados_train, dfdados_test"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 4.4 Análise"]},{"cell_type":"markdown","metadata":{"id":"N2wEm3z-2Lld"},"source":["### Função descarte documentos muito grandes"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1626432398693,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"nPeajX8C2QX-"},"outputs":[],"source":["def descarteDocumentosGrandes1(tamanho_maximo_token, dfdados_train, dfdados_test):\n","\n","  # Define o tamanho máximo para os tokens.\n","  tamanho_maximo = tamanho_maximo_token\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  dfdados_train['input_ids'] = dfdados_train['documento'].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","        \n","  dfdados_train = dfdados_train[dfdados_train['input_ids'].apply(len)\u003ctamanho_maximo]\n","\n","  print('Tamanho do dataset de treino: {}'.format(len(dfdados_train)))\n","\n","  # Remove as colunas desnecessárias.\n","  dfdados_train = dfdados_train.drop(columns=['input_ids'])\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  dfdados_test['input_ids'] = dfdados_test['documento'].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","\n","  # Corta os inputs para o tamanho máximo 512.\n","  dfdados_test = dfdados_test[dfdados_test['input_ids'].apply(len)\u003ctamanho_maximo]\n","\n","  print('Tamanho do dataset de teste: {}'.format(len(dfdados_test)))\n","  \n","  # Remove as colunas desnecessárias.\n","  dfdados_test = dfdados_test.drop(columns=['input_ids'])\n","\n","  return dfdados_train, dfdados_test"]},{"cell_type":"markdown","metadata":{"id":"o6InuUN12wri"},"source":["### Descartando documentos muito grandes"]},{"cell_type":"markdown","metadata":{"id":"_PCYbCqvc8bS"},"source":["### Seleciona as colunas de treino"]},{"cell_type":"markdown","metadata":{"id":"iGR1EHcrLfOB"},"source":["### Seleciona as colunas de teste"]},{"cell_type":"markdown","metadata":{"id":"aRp4O7D295d_"},"source":["### Conjunto de dados em Treinamento \u0026 Teste"]},{"cell_type":"markdown","metadata":{"id":"8bwa6Rts-02-"},"source":["## 4.5 Treinando o modelo de classificação"]},{"cell_type":"markdown","metadata":{"id":"qRWT-D4U_Pvx"},"source":["### Otimizador e Agendador de Taxas de Aprendizado/Optimizer \u0026 Learning Rate Scheduler\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8o-VEBobKwHk"},"source":["Agora que temos nosso modelo carregado, precisamos pegar os hiperparâmetros de treinamento no modelo armazenado.\n","\n","Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (no Apêndice A.3 do [artigo BERT](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","\u003e - **Tamanho do lote(Batch size):** 16, 32\n","- **Taxa de aprendizado (Adam):** 5e-5, 3e-5, 2e-5\n","- **Número de épocas:** 2, 3, 4\n","\n","O parâmetro epsilon `eps = 1e-6` é\" um número muito pequeno para impedir qualquer divisão por zero na implementação \"(a partir de [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n","\n","Você pode encontrar a criação do otimizador do AdamW em `run_glue.py` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."]},{"cell_type":"markdown","metadata":{"id":"MKecsl5K3LR9"},"source":["### Função carrega otimizador\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1626432398694,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"ajnrdhF63N-r"},"outputs":[],"source":["def carregaOtimizador():\n","\n","  '''\n","    Esta função carrega o otimizador utilizado no agendador de aprendizado.\n","  '''\n","\n","  # Import das bibliotecas.\n","  from transformers import AdamW\n","\n","  # Nota: AdamW é uma classe da biblioteca huggingface (ao contrário de pytorch).\n","  # Eu acredito que o 'W' significa 'Correção de redução de peso \"\n","  optimizer = AdamW(model.parameters(),\n","                  lr = training_args.learning_rate, # (ou alfa) A taxa de aprendizado a ser usada. - default é 3e-5\n","                  # betas = (0.9, 0.999), # (beta1, beta2) - default é (0.9, 0.999)\n","                    # beta1 é taxa de decaimento exponencial para as estimativas do primeiro momento. \n","                    # beta2 é taxa de decaimento exponencial para as estimativas do segundo momento. Este valor deve ser definido próximo a 1,0 em problemas com gradiente esparso (por exemplo, PNL e problemas de visão de computacional)\n","                  # eps = 1e-6, #  É um número muito pequeno para evitar qualquer divisão por zero na implementação - default é 1e-6.\n","                  # weight_decay = 0.0, # Correção de redução de peso. - default é 0.0\n","                    # A redução da taxa de aprendizagem também pode ser usada com Adam. A taxa de decaimento é atualizada a cada época para a demonstração da regressão logística.\n","                  # correct_bias = True #  Se não deve corrigir o viés(bias) no Adam mudar para False.- default é True\n","                )\n","  \n","  return optimizer"]},{"cell_type":"markdown","metadata":{"id":"N-Aqb27R3cci"},"source":["### Função carrega agendador"]},{"cell_type":"markdown","metadata":{"id":"W2MT7UK84srM"},"source":["A função **get_linear_schedule_with_warmup** cria um agendador com uma taxa de aprendizado que diminua linearmente da taxa de aprendizagem inicial definido no otimizador até 0, após um período de aquecimento durante o qual ele aumenta linearmente de 0 para a taxa de aprendizagem inicial definido no otimizador.\n","\n","Se `num_warmup_steps=0` e `weight_decay=0`(otimizador) não ocorre a etapa de aquecimento."]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1626432398694,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"XMCaS1VqNr5y"},"outputs":[],"source":["def carregaAgendador():\n","\n","  '''\n","    Esta função carrega o agendador com um taxa de aprendizado que diminua linearmente até 0.\n","  '''\n","\n","  # Import das bibliotecas.\n","  from transformers import get_linear_schedule_with_warmup\n","\n","  # O número total de etapas de ajuste fino é [número de lotes] x [número de épocas].\n","  # (Observe que este não é o mesmo que o número de amostras de ajuste fino).\n","  total_etapas = len(documentos_treino) * training_args.num_train_epochs\n","\n","  #Cria o agendador de taxa de aprendizagem.\n","  scheduler = get_linear_schedule_with_warmup(optimizer, # O otimizador para o qual agendar a taxa de aprendizado.\n","                                            num_warmup_steps = 0, # O número de etapas para a fase de aquecimento. Valor default value em run_glue.py\n","                                            num_training_steps = total_etapas) # O número total de etapas de treinamento.\n","\n","\n","  print(\"Total de etapas: {}\".format(total_etapas))\n","\n","  return scheduler"]},{"cell_type":"markdown","metadata":{"id":"O0my3USqpC45"},"source":["### função: cria_lotes_inteligentes"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1626432398694,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"hGpsZgnDolp9"},"outputs":[],"source":["def cria_lotes_inteligentes1(documentos, classes, documentoids, batch_size):\n","    '''\n","    Esta função combina todos os passos para preparar os lotes.\n","    '''\n","    print('Criando Lotes Inteligentes de {:,} amostras com tamanho de lote {:,}...\\n'.format(len(documentos), batch_size))\n","\n","    # ============================\n","    #   Tokenização \u0026 Truncamento\n","    # ============================\n","\n","    input_ids_completos = []\n","    \n","    # Tokeniza todas as amostras de treinamento\n","    print('Tokenizando {:,} amostra...'.format(len(classes)))\n","    \n","    # Escolha o intervalo que o progresso será atualizado.\n","    intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(classes), numero_atualizacoes=10)\n","    \n","    # Para cada amostra de treinamento...\n","    for documento in documentos:\n","        \n","        # Relatório de progresso\n","        if ((len(input_ids_completos) % intervalo_atualizacao) == 0):\n","            print('  Tokenizado {:,} amostras.'.format(len(input_ids_completos)))\n","\n","        # Tokeniza a amostra.\n","        input_ids = tokenizer.encode(text=documento,                    # Documento a ser codificado.\n","                                    add_special_tokens=True,            # Adiciona os ttokens especiais.\n","                                    max_length=model_args.max_seq_len,  # Tamanho do truncamento!\n","                                    truncation=True,                    # Faz o truncamento!\n","                                    padding=False)                      # Não preenche.\n","                \n","        # Adicione o resultado tokenizado à nossa lista.\n","        input_ids_completos.append(input_ids)\n","        \n","    print('FEITO.')\n","    print('{:\u003e10,} amostras\\n'.format(len(input_ids_completos)))\n","\n","    # =========================\n","    #      Seleciona os Lotes\n","    # =========================    \n","    \n","    # Classifique as duas listas pelo comprimento da sequência de entrada.\n","    amostras = sorted(zip(input_ids_completos, classes, documentoids), key=lambda x: len(x[0]))\n","\n","    print('{:\u003e10,} amostras após classificação\\n'.format(len(amostras)))\n","\n","    import random\n","\n","    # Lista de lotes que iremos construir.\n","    batch_ordered_documentos = []\n","    batch_ordered_classes = []\n","    batch_ordered_documentoids = []\n","\n","    print('Criando lotes de tamanho {:}...'.format(batch_size))\n","\n","    # Escolha um intervalo no qual imprimir atualizações de progresso.\n","    intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(amostras), numero_atualizacoes=10)\n","        \n","    # Faça um loop em todas as amostras de entrada ... \n","    while len(amostras) \u003e 0:\n","        \n","        # Mostra o progresso.\n","        if ((len(batch_ordered_documentos) % intervalo_atualizacao) == 0 \\\n","            and not len(batch_ordered_documentos) == 0):\n","            print('  Selecionado {:,} lotes.'.format(len(batch_ordered_documentos)))\n","        \n","        # `to_take` é o tamanho real do nosso lote. Será `batch_size` até\n","        # chegamos ao último lote, que pode ser menor.\n","        to_take = min(batch_size, len(amostras))\n","        \n","        # Escolha um índice aleatório na lista de amostras restantes para começar o nosso lote.\n","        select = random.randint(0, len(amostras) - to_take)\n","\n","        # Selecione um lote contíguo de amostras começando em `select`.\n","        #print (\"Selecionando lote de {:} a {:}\".format(select, select+to_take))\n","        batch = amostras[select:(select + to_take)]\n","\n","        #print(\"Tamanho do lote:\", len(batch))\n","        \n","        # Cada amostra é uma tupla --divida para criar uma lista separada de\n","        # sequências e uma lista de rótulos para este lote.\n","        batch_ordered_documentos.append([s[0] for s in batch])\n","        batch_ordered_classes.append([s[1] for s in batch])\n","        batch_ordered_documentoids.append([s[2] for s in batch])\n","        \n","        # Remova a amostra da lista\n","        del amostras[select:select + to_take]\n","\n","    print('\\n  FEITO - Selecionado {:,} lotes.\\n'.format(len(batch_ordered_documentos)))\n","\n","    # =========================\n","    #        Adicionando o preenchimento\n","    # =========================    \n","\n","    print('Preenchendo sequências dentro de cada lote...')\n","\n","    py_input_ids = []\n","    py_attention_masks = []\n","    py_labels = []\n","    list_documentoids = []\n","\n","    # Para cada lote...\n","    for (batch_input_ids, batch_labels, batch_documentoids) in zip(batch_ordered_documentos, batch_ordered_classes, batch_ordered_documentoids):\n","\n","        # Nova versão do lote, desta vez com sequências preenchidas e agora com\n","        # as máscaras de atenção definidas.\n","        batch_padded_input_ids = []\n","        batch_attention_masks = []\n","                \n","        # Primeiro, encontre a amostra mais longa do lote.\n","        # Observe que as sequências atualmente incluem os tokens especiais!\n","        max_size = max([len(input) for input in batch_input_ids])\n","        \n","        # Para cada entrada neste lote...\n","        for input in batch_input_ids:\n","                        \n","            # Quantos tokens pad precisam ser adicionados\n","            num_pads = max_size - len(input)\n","\n","            # Adiciona `num_pads` do pad token(tokenizer.pad_token_id) até o final da sequência.\n","            padded_input = input + [tokenizer.pad_token_id] * num_pads\n","\n","            # Define a máscara de atenção --é apenas um `1` para cada token real\n","            # e um `0` para cada token de preenchimento(pad).\n","            attention_mask = [1] * len(input) + [0] * num_pads\n","            \n","            # Adiciona o resultado preenchido ao lote.\n","            batch_padded_input_ids.append(padded_input)\n","            batch_attention_masks.append(attention_mask)\n","        \n","        # Nosso lote foi preenchido, portanto, precisamos salvar este lote atualizado.\n","        # Também precisamos que as entradas sejam tensores PyTorch, então faremos isso aqui.\n","        py_input_ids.append(torch.tensor(batch_padded_input_ids))\n","        py_attention_masks.append(torch.tensor(batch_attention_masks))\n","        py_labels.append(torch.tensor(batch_labels))\n","        list_documentoids.append(batch_documentoids)\n","    \n","    # Retorna o conjunto de dados em lotes inteligentes!\n","    return (py_input_ids, py_attention_masks, py_labels, list_documentoids)"]},{"cell_type":"markdown","metadata":{"id":"Thh-qfv5q4tI"},"source":["### Função de Treinamento"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":591,"status":"ok","timestamp":1626432399264,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"ox8cl_CZDxc-"},"outputs":[],"source":["# Import das bibliotecas\n","import random\n","import numpy as np\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaTreinamento(documentos_treino, classes_treino, documentoids_treino, EPOCAS = 4):\n","  \n","  print(\"\\nRealizando Treinamento fold: {}\".format(model_args.fold))\n","\n","  # Defina o valor da semente em todos os lugares para torná-lo reproduzível.\n","  seed_val = training_args.seed\n","\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  # Atualize todos os lotes ʻintervalo_atualizacao`.\n","  intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(documentos_treino), numero_atualizacoes=10)\n","\n","  # Medida do tempo total de treinamento.\n","  treinamento_t0 = time.time()\n","\n","  # Limpa o cache da GPU.\n","  torch.cuda.empty_cache()\n","\n","  # Coloque o modelo em modo de treinamento. \n","  model.train()\n","\n","  # Acumula as perdas do treinamento.\n","  train_losses = []\n","\n","  if model_args.use_wandb:\n","    # Log das métricas com wandb.\n","    wandb.watch(model)\n","\n","  # Barra de progresso da época.\n","  epoca_bar = tqdm_notebook(range(training_args.num_train_epochs), desc=f'Épocas', unit=f'épocas')\n","\n","  # Para cada época.\n","  for epoca_i in epoca_bar:\n","    \n","    # ========================================\n","    #               Treinamento\n","    # ========================================\n","    \n","    # Execute uma passada completa sobre o conjunto de treinamento.\n","\n","    # Recupera o lote inteligente\n","    #(py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(documentos_treino, classes_treino, documentoids_treino, training_args.per_device_train_batch_size)\n","    (py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(model_args, tokenizer, documentos_treino, classes_treino, documentoids_treino, training_args.per_device_train_batch_size)\n","\n","    # Medida de quanto tempo leva o período de treinamento.\n","    treinamento_epoca_t0 = time.time()\n","\n","    # Acumula as perdas do treinamento da época.\n","    train_epoca_losses = []\n","\n","    # Barras de progresso.    \n","    lote_treino_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Epoca {epoca_i+1}', unit=f'lotes', total=len(py_input_ids) )\n","\n","    # Para cada lote dos dados de treinamento.\n","    for index in lote_treino_bar:      \n","\n","        # Progresso é atualizado a cada lotes, por exemplo, 100 lotes.\n","        if index % intervalo_atualizacao == 0 and not index == 0:            \n","            # Calcula gasto o tempo em minutos.\n","            tempoGasto = formataTempo(time.time() - treinamento_epoca_t0)\n","                        \n","            # Calcule o tempo restante com base em nosso progresso.\n","            passos_por_segundo = (time.time() - treinamento_epoca_t0) / index\n","            segundos_restantes = passos_por_segundo * (len(py_input_ids) - index)\n","            tempoRestante = formataTempo(segundos_restantes)\n","\n","            # Mostra o progresso.\n","            print('  Lote {:\u003e7,}  de  {:\u003e7,}.    Gasto: {:}.  Restante: {:}'.format(index, len(py_input_ids), tempoGasto, tempoRestante))\n","\n","        # Descompacte este lote de treinamento de nosso dataloader.\n","        #\n","        # À medida que descompactamos o lote, também copiaremos cada tensor para a GPU usando o\n","        # o método `to`\n","        #\n","        # `lote` é uma lista contém três tensores pytorch:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","\n","        # Recupera os tensores do lote e copia para a GPU usando o método `to` \n","        d_input_ids = py_input_ids[index].to(device)\n","        d_input_mask = py_attention_masks[index].to(device)\n","        d_labels = py_labels[index].to(device)     \n","        \n","        # Sempre limpe quaisquer gradientes calculados anteriormente antes de realizar um\n","        # passe para trás. PyTorch não faz isso automaticamente porque\n","        # acumular os gradientes é \"conveniente durante o treinamento de RNNs\".\n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()\n","\n","        # Execute um passe para frente (avalie o modelo neste lote de treinamento).\n","        # A documentação para esta função `model` está aqui:\n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # Ele retorna diferentes números de parâmetros dependendo de quais argumentos\n","        # são fornecidos e quais sinalizadores estão definidos. Para nosso uso aqui, ele retorna\n","        # a perda (porque fornecemos rótulos) e os \"logits\" - o modelo de saídas antes da ativação.     \n","\n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","        # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels))                  \n","        loss = outputs[0]\n","\n","        # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","        # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","        # A função `.detach().cpu()` retira da gpu.\n","        logits = outputs[1].detach().cpu()\n","  \n","        # Acumule a perda de treinamento em todos os lotes da época para que possamos\n","        # calcular a perda média no final da época. `loss` é um tensor contendo um único valor.   \n","        # A função `.item ()` retorna apenas o valor Python do tensor.\n","        train_epoca_losses.append(loss.item())\n","\n","        # Mostra a perda na barra de progresso.\n","        lote_treino_bar.set_postfix(loss=loss.item())\n","\n","        if model_args.use_wandb:\n","          wandb.log({\"train_batch_loss\": loss.item()})\n","\n","        # Execute uma passagem para trás para calcular os gradientes.\n","        # Todos os parâmetros do modelo deve ter sido setado para param.requires_grad = False\n","        loss.backward()            \n","\n","        # Corte a norma dos gradientes para 1.0.\n","        # Isso ajuda a evitar o problema de \"gradientes explosivos\".\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","       \n","        # Atualize os parâmetros e dê um passo usando o gradiente calculado.\n","        # O otimizador dita a \"regra de atualização\" - como os parâmetros são\n","        # modificados com base em seus gradientes, taxa de aprendizagem, etc.\n","        optimizer.step()\n","                           \n","        # Atualize a taxa de aprendizagem.\n","        scheduler.step()\n","\n","        del outputs\n","\n","    # Média da perda do treinamento de todos os lotes da época.\n","    media_train_epoca_loss = np.mean(train_epoca_losses)\n","\n","    # Acumule a perda de treinamento de todas as épocas para calcular a perda média do treinamento.    \n","    train_losses.append(media_train_epoca_loss)\n","\n","    if model_args.use_wandb:\n","        wandb.log({\"media_train_epoca_loss\": media_train_epoca_loss})           \n","        \n","    # Medida de quanto tempo levou essa época.\n","    treinamento_epoca_total = formataTempo(time.time() - treinamento_epoca_t0)\n","\n","    print(\"  Média perda(loss) do treinamento da época : {0:.8f}\".format(media_train_epoca_loss))\n","    print(\"  Tempo de treinamento da época             : {:}\".format(treinamento_epoca_total))    \n","    print(\"  Tempo parcial do treinamento              : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_t0)))\n","\n","    del py_input_ids\n","    del py_attention_masks\n","    del py_labels\n","    del train_epoca_losses\n","    del lote_treino_bar\n","  \n","  # Média da perda do treinamento de todas as épocas.\n","  media_train_loss = np.mean(train_losses)\n","\n","  if model_args.use_wandb:\n","    wandb.log({\"media_train_loss\": media_train_loss})   \n","\n","  print(\"  Média perda(loss) treinamento : {0:.8f}\".format(media_train_loss))\n","\n","  del train_losses\n","  del epoca_bar\n","\n","  print(\"Treinamento completo!\")"]},{"cell_type":"markdown","metadata":{"id":"av-_hPByrUCA"},"source":["# 5 Avaliação\n","\n","Avaliando o modelo treinado no conjunto de dados de teste."]},{"cell_type":"markdown","metadata":{"id":"teXptLZNjszT"},"source":["## 5.1 Função de Avaliação"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1626432399264,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"R8DIJXnmjw5v"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaAvaliacao(documentos_teste, classes_teste, documentoids_teste):\n","\n","  # Armazena o resultado da avaliação executada\n","  lista_resultado_avaliacao = []\n","\n","  print(\"\\nRealizando Avaliação fold: {}\".format(model_args.fold))\n","\n","  # Predição no conjunto de teste no modelo.\n","  print('Predizendo rótulos para {:,} documentos de teste...'.format(len(documentos_teste)))\n","\n","  # Use nossa nova função para preparar completamente nosso conjunto de dados.\n","  #(py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(documentos_teste, classes_teste, documentoids_teste, training_args.per_device_eval_batch_size)\n","  (py_input_ids, py_attention_masks, py_labels, documentoids) = cria_lotes_inteligentes(model_args, tokenizer, documentos_teste, classes_teste, documentoids_teste, training_args.per_device_eval_batch_size)\n","\n","  # Escolha um intervalo para imprimir atualizações de progresso.\n","  intervalo_atualizacao = obter_intervalo_atualizacao(total_iteracoes=len(py_input_ids), numero_atualizacoes=10)\n","\n","  # Coloque o modelo em modo de avaliação.\n","  model.eval()\n","\n","  # Acumula as perdas.\n","  test_losses = []\n","\n","  totalacuracia = 0\n","\n","  # Acumula os resultados dos testes.\n","  vp = [] # Verdadeiro positivo\n","  vn = [] # Verdadeiro negativo\n","  fp = [] # Falso positivo\n","  fn = [] # Falso negativo\n","\n","  # Barra de progresso dos lotes de teste.\n","  lote_teste_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Lotes ', unit=f'lotes', total=len(py_input_ids))\n","\n","  # Para cada lote dos dados de avaliação(teste).\n","  for index in lote_teste_bar:\n","\n","    # Progresso é atualizado a cada lotes, por exemplo, 100 lotes.\n","    if index % intervalo_atualizacao == 0 and not index == 0:        \n","        # Calcula o tempo gasto em minutos.\n","        tempoGasto = formataTempo(time.time() - avaliacao_t0)\n","        \n","        # Calcula o tempo restante baseado no progresso.\n","        passos_por_segundo = (time.time() - avaliacao_t0) / index\n","        segundos_restantes = passos_por_segundo * (len(py_input_ids) - index)\n","        tempoRestante = formataTempo(segundos_restantes)\n","\n","        # Mostra o progresso.\n","        print('  Lote {:\u003e7,}  de  {:\u003e7,}.    Gasto: {:}.  Restando: {:}'.format(index, len(py_input_ids), tempoGasto, tempoRestante))\n","    \n","    # Copia o lote para a GPU.\n","    d_input_ids = py_input_ids[index].to(device)\n","    d_input_mask = py_attention_masks[index].to(device)\n","    d_labels = py_labels[index].to(device)\n","    d_documentoids = documentoids[index]\n","\n","    # Diga a pytorch para não se preocupar em construir o gráfico de computação durante\n","    # o passe para frente, já que isso só é necessário para backprop (treinamento).\n","    with torch.no_grad():\n","        # Obtenha a saída de \"logits\" pelo modelo. Os \"logits\" são a saída\n","        # valores antes de aplicar uma função de ativação como o softmax.        \n","        # Retorno de model quando ´last_hidden_state=True´ é setado:    \n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids,\n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","    # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels). \n","    # É útil para comparar com a perda do treinamento, quando é realizado a avaliação entre as épocas de treinamento.\n","    loss = outputs[0]\n","\n","    # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","    # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","    logits = outputs[1]\n","        \n","    # Acumule a perda da avaliação em todos os lotes para que possamos\n","    # calcular a perda média no final. `loss` é um tensor contendo um único valor.\n","    # A função '.cpu()' move loss para a cpu.\n","    # A função `.item ()` retorna apenas o valor Python do tensor.         \n","    test_losses.append(loss.cpu().item())\n","\n","    # Recupera o índice do melhor resultado, maior valor dos tensores para coluna(1)\n","    _, classificacao = torch.max(logits, 1)\n","\n","    # Verifica a classificação realizada e o rótulo previsto\n","    vp.append(((classificacao==1) \u0026 (d_labels==1)).sum().cpu().item())\n","    vn.append(((classificacao==0) \u0026 (d_labels==0)).sum().cpu().item())\n","    fp.append(((classificacao==1) \u0026 (d_labels==0)).sum().cpu().item())\n","    fn.append(((classificacao==0) \u0026 (d_labels==1)).sum().cpu().item())\n","\n","    # Adiciona o documento de teste, o rótulo e a classificação realizada a lista de resultado\n","    for lote in range(len(d_labels)):\n","                \n","        lista_resultado_avaliacao.append([d_documentoids[lote],\n","                                d_labels[lote].cpu().item(), \n","                                classificacao[lote].cpu().item()])\n","\n","    del outputs\n","\n","  # Soma as classificações realizadas\n","  vp_s, vn_s, fp_s, fn_s = sum(vp), sum(vn), sum(fp), sum(fn)\n","  \n","  # Acurácia indica uma performance geral do modelo. \n","  # Dentre todas as classificações, quantas o modelo classificou corretamente(vp=1 e vn=0).\n","  acc = (vp_s+vn_s)/(vp_s+vn_s+fp_s+fn_s)\n","\n","  # Recall(Revocação) avalia todas as situações da classe Positivo(vp=1) com o valor esperado e quantas estão corretas.\n","  if (vp_s+fn_s) != 0:\n","      rec = (vp_s)/(vp_s+fn_s)\n","  else:\n","      rec = 0\n","  \n","  # Precisão avalia as classificações da classe positivo(vp=1 e fp=0) que o modelo fez e quantas estão corretas.\n","  if (vp_s+fp_s) != 0:\n","      pre = (vp_s)/(vp_s+fp_s)\n","  else:\n","      pre = 0  \n","\n","  # F1 é a média harmônica entre precisão e recall.\n","  if (pre + rec) != 0:  \n","    f1 = 2 * ((pre * rec)/(pre + rec))\n","  else:\n","    f1 = 0\n","\n","  # Média da perda da avaliação  \n","  media_test_loss = np.mean(test_losses)\n","\n","  if model_args.use_wandb:\n","    # Log do wandb\n","    wandb.log({\"acuracia\": acc})\n","    wandb.log({\"vp\": vp_s})\n","    wandb.log({\"vn\": vn_s})\n","    wandb.log({\"fp\": fp_s})\n","    wandb.log({\"fn\": fn_s})\n","    wandb.log({\"media_test_loss\": media_test_loss})\n","\n","  del py_input_ids\n","  del py_attention_masks\n","  del py_labels\n","  del test_losses\n","  del lote_teste_bar\n","\n","  return media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao"]},{"cell_type":"markdown","metadata":{"id":"VtblUQT0EAO5"},"source":["## 5.2 Salvando o resultado da classificação"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1626432399265,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"vnu6iKHwAaTb"},"outputs":[],"source":["def salvaResultadoClassificacao(lista_resultado_avaliacao):\n","\n","  if model_args.salvar_classificacao:\n","\n","    # Import das bibliotecas.\n","    import os\n","    import datetime\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_CLASSIFICACAO = training_args.output_dir + str(model_args.fold) + MODELO_BERT + TAMANHO_BERT \n","  \n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_CLASSIFICACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_CLASSIFICACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_CLASSIFICACAO)\n","      print('Diretório criado: {}'.format(DIRETORIO_CLASSIFICACAO))\n","    else:\n","      print('Diretório já existe: {}'.format(DIRETORIO_CLASSIFICACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_CLASSIFICACAO_COMPLETO = DIRETORIO_CLASSIFICACAO + NOME_ARQUIVO_CLASSIFICACAO + \".csv\"\n","\n","    # Gera todo o conteúdo a ser salvo no arquivo\n","    novoConteudo = \"\"        \n","    for resultado in lista_resultado_avaliacao:      \n","      novoConteudo = novoConteudo + data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\" + str(resultado[0]) + \";\" + str(resultado[1]) + \";\" + str(resultado[2]) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO):\n","      print(\"Atualizando arquivo classificação: {}\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novoConteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","    else:\n","      print(\"Criando arquivo classificação: {}\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      arquivo.writelines('data;id;classe;predicao\\n' + novoConteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"DloA0HIShFzW"},"source":["## 5.3 Salvando o resultado da avaliação"]},{"cell_type":"markdown","metadata":{"id":"PUjV5m1X_TYH"},"source":["### Salva o resultado da avaliação \n","\n","Salva o resultado da avaliação do conjunto de dados de teste do fold especificado."]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1626432399265,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"4aiVdm7P_TlV"},"outputs":[],"source":["def salvaResultadoAvaliacao():\n","\n","  if model_args.salvar_avaliacao:\n","\n","    # Import das bibliotecas.\n","    import os\n","    import datetime\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_AVALIACAO = training_args.output_dir + str(model_args.fold) + MODELO_BERT + TAMANHO_BERT \n","\n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_AVALIACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_AVALIACAO)\n","      print('Diretório criado: {}'.format(DIRETORIO_AVALIACAO))\n","    else:\n","      print('Diretório já existe: {}'.format(DIRETORIO_AVALIACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + \".csv\"\n","\n","    # Conteúdo a ser adicionado.\n","    novoConteudo = NOME_ARQUIVO_AVALIACAO + \";\" +  data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\"  + treinamento_total + \";\"  + str(acc) + \";\"  +  str(vp_s) + \";\"  +  str(vn_s) + \";\" +  str(fp_s) + \";\" +  str(fn_s) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      print(\"Atualizando arquivo resultado: {}\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novoConteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","    else:\n","      print(\"Criando arquivo resultado: {}\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      arquivo.writelines('arquivo;data;tempo;acuracia;vp;vn;fp;fn\\n' + novoConteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"bUskOwzJmpDB"},"source":["### Carrega e calcula a média da acurácia dos folds\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1626432399265,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"},"user_tz":180},"id":"C7e4KBUq5iHF"},"outputs":[],"source":["def carregaResultadoAvaliacao():\n","\n","  # Import das bibliotecas.\n","  import os\n","  import pandas as pd\n","\n","  # Acumuladores.\n","  somaAcuracia = 0\n","  listaTempo = []\n","  contaFolds = 0\n","\n","  # Nome arquivo resultado avaliação\n","  NOME_ARQUIVO_AVALIACAO = training_args.output_dir\n","\n","  print(\"Média dos arquivos: \", NOME_ARQUIVO_AVALIACAO + \"X\" + TAMANHO_BERT)\n","\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/\"\n","\n","  # Verifica se o diretório dos resultados existem.\n","  if os.path.exists(DIRETORIO_AVALIACAO):\n","    # Percorre os arquivos de resultados.\n","    for f in range(10):  \n","      # Nome do arquivo a ser aberto.\n","      NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + str(f+1) + MODELO_BERT + TAMANHO_BERT + \".csv\"    \n","      # Verifica se o arquivo existe.\n","      if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","        # Carrega os dados do arquivo  \n","        dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","        # Mostra os dados do teste do fold.\n","        for index, linha in dados.iterrows():\n","        \n","          # Cálculo das estatísticas\n","          acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])\n","          if (linha['vp']+linha['fn']) != 0:\n","              rec = (linha['vp'])/(linha['vp']+linha['fn'])\n","          else:\n","              rec = 0\n","          if (linha['vp']+linha['fp']) != 0:\n","              pre = (linha['vp'])/(linha['vp']+linha['fp'])\n","          else:  \n","              pre = 0\n","          if (pre + rec) != 0:  \n","              f1 = 2 * ((pre * rec)/(pre + rec))\n","          else:\n","              f1 = 0\n","          qtdeTestes = linha['vp']+linha['vn']+linha['fp']+linha['fn']\n","          print('Arquivo: {}, Data: {}, Tempo: {}, QtdeTeste: {:3d}, Acc: {:.8f}, Rec: {:.8f}, Pre: {:.8f}, F1:{:.8f}, vp: {:4d}; vn: {:4d}; fp: {:4d}; fn: {:4d}'.format( \n","               linha['arquivo'], linha['data'], linha['tempo'], qtdeTestes, acc, rec, pre, f1, linha['vp'], linha['vn'], linha['fp'], linha['fn']))    \n","           \n","          # Guarda o tempo.\n","          listaTempo.append(str(linha['tempo']))\n","\n","        # Procura a maior acurácia.\n","        somaAcuracia = somaAcuracia + dados['acuracia'].max()\n","        # Conta o número de folds.\n","        contaFolds = contaFolds + 1\n","    \n","    # Mostra a soma da acurácia . \n","    print('Total acurácia                                       : {:.8f}'.format(somaAcuracia))\n","    # Mostra a quantidade de folds.\n","    print('Quantidade de folds                                  : {}'.format(contaFolds))  \n","    # Calcula a média.\n","    media = somaAcuracia/contaFolds\n","    print('A média da acurácia de {:2d} folds é                    : {:.8f}'.format(contaFolds, media))\n","    print('O tempo gasto na execução do treinamentoa {:2d} folds é : {}'.format(contaFolds, somaTempo(listaTempo)))\n","    print('A média de tempo de execução de {:2d} folds é           : {}'.format(contaFolds, mediaTempo(listaTempo)))\n","  else:\n","    print('Diretório com os resultados não encontrado')"]},{"cell_type":"markdown","metadata":{"id":"MPRD4HkL2Ymp"},"source":["## 5.4 Execução do treinamento e avaliação de todos os Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":611},"id":"XTt9_BAS2adF"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processamendo do fold: 1\n","  Tempo de início de processamento fold:  1626432399.910835 (h:mm:ss)\n","Pasta do /content/modelo pronta!\n","Usando modelo pré-treinado de download ou comunidade\n","Carregando o modelo BERT do diretório /content/modelo para classificação.\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at /content/modelo were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/modelo and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Carregando o tokenizador BERT do diretório /content/modelo...\n","Pytorch rodando sem GPU\n","Copiando do checkout do Github\n","Diretório criado: /content/validacao_kfold\n","Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f1.csv\n","Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f1.csv\n","Qtde de dados de treino: 8964\n","Qtde de dados de teste: 996\n","Removendo documentos grandes, acima de  512  tokens.\n"]},{"name":"stderr","output_type":"stream","text":["2021-07-16 10:47:49,334 : INFO : NumExpr defaulting to 2 threads.\n"]},{"name":"stdout","output_type":"stream","text":["Tamanho do dataset de treino: 8964\n","Tamanho do dataset de teste: 996\n","Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n","Total de etapas: 8964\n","\n","Realizando Treinamento fold: 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8cb8e1deb7884cb1a5c7db977f7f1eaf","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Épocas', max=1.0, style=ProgressStyle(description_width='…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"977251fc61394b14b9209bf755dfe178","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoca 1', max=2241.0, style=ProgressStyle(description_wid…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Lote     900  de    2,241.    Gasto: 3:04:21.  Restante: 4:34:41\n"]}],"source":["# Import das bibliotecas\n","import time\n","import datetime\n","from conjuntodedados.dadoscstnewsclassificacao import *\n","\n","# Percorre todos os folds do intervalo de inicioFold até fimFold\n","for ifold in range(inicioFold,fimFold+1):\n","\n","  # Seta o parâmetro do fold\n","  model_args.fold = ifold\n","  print(\"\\nProcessamendo do fold: {}\".format(model_args.fold))\n","  \n","  # Marca o tempo de início do processamento\n","  inicioProcessamentof = time.time()\n","\n","  print(\"  Tempo de início de processamento fold:  {:} (h:mm:ss)\".format(inicioProcessamentof))\n","\n","  # Carrega o modelo e tokenizador do BERT\n","  model, tokenizer = carregaBERT(model_args)\n","\n","  # Conecta o modelo a GPU\n","  model = conectaGPU(model, device)\n","\n","  # Inicializa o wandb para registro\n","  wandb = inicializacaoWandb()\n","\n","  # Função de carregamento dos dados de um fold\n","  dfdados_train, dfdados_test = getConjuntoDeDadosClassificacaoKFold(model_args, tokenizer, ORIGEM=None)\n","\n","  # Pega as listas de documentos de treino e seus rótulos.\n","  documentos_treino = dfdados_train.documento.values\n","  classes_treino = dfdados_train.classe.values\n","  documentoids_treino = dfdados_train.id.values\n","\n","  # Pega as listas de documentos teste e seus rótulos.\n","  documentos_teste = dfdados_test.documento.values\n","  classes_teste = dfdados_test.classe.values\n","  documentoids_teste = dfdados_test.id.values\n","\n","  # Mostra o resultado dos dados carregados.\n","  print(\"Total do conjunto de dados          : {}.\".format(len(documentos_treino) + len(documentos_teste)))\n","  print(\"Total do conjunto de dados de treino: {}.\".format(len(documentos_treino)))\n","  print(\"Total do conjunto de dados de teste : {}.\".format(len(documentos_teste)))\n","\n","  #################  Treinamento\n","\n","  # Carrega o otimizador\n","  optimizer = carregaOtimizador()\n","\n","  # Carrega o agendador\n","  scheduler = carregaAgendador()\n","\n","  # Registra o tempo inicial.\n","  treinamento_t0 = time.time()\n","\n","  # Realiza o treinamento.\n","  realizaTreinamento(documentos_treino, classes_treino, documentoids_treino, training_args.num_train_epochs)\n","  \n","  # Medida de quanto tempo levou a execução do treinamento.\n","  treinamento_total = formataTempo(time.time() - treinamento_t0)\n","\n","  print(\"  Tempo total treinamento       : {:}\".format(treinamento_total))\n","  \n","  #################  Treinamento\n","\n","  ################# Avaliação\n","\n","  # Registra o tempo inicial.\n","  avaliacao_t0 = time.time()\n","\n","  # Realiza a avaliação do modelo.\n","  media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(documentos_teste, classes_teste, documentoids_teste)\n","\n","  print('Avaliação loss: {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}'.format( \n","        media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))      \n","    \n","  print(\"Acurácia do fold {}        : {:.8f}\".format(model_args.fold, acc))  \n","\n","  # Medida de quanto tempo levou a execução do treinamento e avaliação\n","  avaliacao_total = formataTempo(time.time() - avaliacao_t0)\n","\n","  print(\"Tempo gasto na avaliação  : {:}\".format(avaliacao_total))\n","\n","  ################# Avaliação\n","\n","  # Salva o resultado da classificação\n","  salvaResultadoClassificacao(lista_resultado_avaliacao)\n","\n","  # Salva o resultado da avaliação\n","  salvaResultadoAvaliacao()\n","\n","  # Apaga os dados\n","  del dfdados_train\n","  del dfdados_test\n","  del documentos_treino\n","  del classes_treino\n","  del documentoids_treino\n","  del documentos_teste\n","  del classes_teste\n","  del documentoids_teste\n","  del lista_resultado_avaliacao\n","  del optimizer\n","  del scheduler\n","  del model\n","\n","  # Pega o tempo atual menos o tempo do início do processamento.\n","  finalProcessamentof = time.time()\n","  tempoTotalProcessamentof = formataTempo(finalProcessamentof - inicioProcessamentof)\n","\n","  print(\"\")\n","  print(\"  Tempo processamento fold: {:} (h:mm:ss)\".format(tempoTotalProcessamentof))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BahqkebDFOye"},"outputs":[],"source":["carregaResultadoAvaliacao()"]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Q_zqfWmlIjMc"},"source":["## 6.1 Salvando o Modelo para o wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9U-parMIj00"},"outputs":[],"source":["if model_args.use_wandb and model_args.salvar_modelo_wandb:\n","  \n","    # Salva o modelo para o wandb    \n","    torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model_dict.pt'))"]},{"cell_type":"markdown","metadata":{"id":"q2079Qyn8Mt8"},"source":["## 6.2 Salvando o Modelo Ajustado\n","\n","Grava o modelo e o tokenizador no disco."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ulTWaOr8QNY"},"outputs":[],"source":["def salvaModelo():\n","  \n","  if model_args.salvar_modelo:\n","  \n","    # Import de bibliotecas.\n","    import os\n","\n","    # Salvando as melhores práticas: se você usar nomes padrão para o modelo, você pode recarregá-lo usando from_pretrained ()\n","\n","    # Diretório de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/'\n","\n","    # Cria o diretório de saída se necessário.\n","    if not os.path.exists(DIRETORIO_LOCAL_MODELO_AJUSTADO):\n","      os.makedirs(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    print('Salvando o modelo para {}'.format(DIRETORIO_LOCAL_MODELO_AJUSTADO))\n","\n","    # Salve um modelo treinado, configuração e tokenizer usando `save_pretrained ()`.\n","    # Eles podem então ser recarregados usando `from_pretrained ()`.\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Cuide do treinamento distribuído/paralelo\n","    model_to_save.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","    tokenizer.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    # Boa prática: salve seus argumentos de treinamento junto com o modelo treinado.\n","    torch.save (model_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'mode_args.bin'))\n","    torch.save (training_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'training_args.bin'))"]},{"cell_type":"markdown","metadata":{"id":"Z-tjHkR7lc1I"},"source":["Vamos verificar os tamanhos dos arquivos, por curiosidade."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqMzI3VTCZo5"},"outputs":[],"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=K /content/modelo_ajustado/"]},{"cell_type":"markdown","metadata":{"id":"fr_bt2rFlgDn"},"source":["O maior arquivo é o peso do modelo, em torno de 416MB o base e 1.25G o large."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WUFUIQ8Cu8D"},"outputs":[],"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=M /content/modelo_ajustado/pytorch_model.bin"]},{"cell_type":"markdown","metadata":{"id":"dzGKvOFAll_e"},"source":["Para salvar seu modelo nas sessões do Colab Notebook, faça o download no seu computador local ou, idealmente, copie-o no seu Google Drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxlZsafTC-V5"},"outputs":[],"source":["if model_args.salvar_modelo:\n","\n","  # Importando as bibliotecas.\n","  import os\n","  \n","  # Diretório local de salvamento do modelo.\n","  DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/'\n","\n","  # Diretório remoto de salvamento do modelo.  \n","  DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/modelo/modelo\" + MODELO_BERT + TAMANHO_BERT\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_REMOTO_MODELO_AJUSTADO):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_REMOTO_MODELO_AJUSTADO)\n","    print('Diretório criado: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","  else:\n","    print('Diretório já existe: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","\n","  ## Copia o arquivo do modelo para o diretório no Google Drive.\n","  !cp -r '$DIRETORIO_LOCAL_MODELO_AJUSTADO'* '$DIRETORIO_REMOTO_MODELO_AJUSTADO'\n","\n","  print(\"Modelo copiado!\")"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.3 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha"},"outputs":[],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","finalProcessamento = time.time()\n","tempoTotalProcessamento = formataTempo(finalProcessamento - inicioProcessamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento: {:} (h:mm:ss)\".format(tempoTotalProcessamento))"]},{"cell_type":"markdown","metadata":{"id":"CeSarQ7N0su4"},"source":["Executa o wandb para finalizar a execução anterior"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIsky8teJ_ki"},"outputs":[],"source":["if model_args.use_wandb:\n","    # Importando a biblioteca.\n","    import wandb\n","    \n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_v1_c_sb_kfold\", name=training_args.output_dir + str(model_args.fold))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"GITHUBAjusteFinoCSTNews_v1_C_SB_KFold_Todos.ipynb","provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"072763bfeaab4b8aaa7109977b16fd59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12637f0f7eb44e0cbce1d098206ddf22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"1d31092c6b5c4ec0949dca4ad7e4d539":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d35684e86cc441cad2c4a73e307476e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26462e4e378e4d5eb2983049a591002e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67fdaff5bf6a416da3e4a71a7186ad64","placeholder":"​","style":"IPY_MODEL_072763bfeaab4b8aaa7109977b16fd59","value":" 0/1 [00:00\u0026lt;?, ?épocas/s]"}},"461a76713e5b42dead19463f056f10ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da6d73979ff46b8a0f226104c785423":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Épocas:   0%","description_tooltip":null,"layout":"IPY_MODEL_1d35684e86cc441cad2c4a73e307476e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d789a6509821447bb813b2a4e8aea870","value":0}},"67fdaff5bf6a416da3e4a71a7186ad64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8631849c0ed346808520f4555486a983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa24827e9e84a6f861e88b5ecb60377":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a10135444d8549668d4bd6f494409842","placeholder":"​","style":"IPY_MODEL_1d31092c6b5c4ec0949dca4ad7e4d539","value":" 1082/2241 [3:41:21\u0026lt;4:18:18, 13.37s/lotes, loss=3.11]"}},"8cb8e1deb7884cb1a5c7db977f7f1eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4da6d73979ff46b8a0f226104c785423","IPY_MODEL_26462e4e378e4d5eb2983049a591002e"],"layout":"IPY_MODEL_461a76713e5b42dead19463f056f10ce"}},"977251fc61394b14b9209bf755dfe178":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fddf6fc44f124939b3706d8c148624a4","IPY_MODEL_8aa24827e9e84a6f861e88b5ecb60377"],"layout":"IPY_MODEL_f255986d9fc14c09a797f640ce41a0ae"}},"a10135444d8549668d4bd6f494409842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d789a6509821447bb813b2a4e8aea870":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"f255986d9fc14c09a797f640ce41a0ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fddf6fc44f124939b3706d8c148624a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Epoca 1:  48%","description_tooltip":null,"layout":"IPY_MODEL_8631849c0ed346808520f4555486a983","max":2241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12637f0f7eb44e0cbce1d098206ddf22","value":1082}}}}},"nbformat":4,"nbformat_minor":0}