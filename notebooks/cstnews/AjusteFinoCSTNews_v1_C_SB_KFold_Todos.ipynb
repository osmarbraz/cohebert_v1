{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AjusteFinoCSTNews_v1_C_SB_KFold_Todos.ipynb","provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ec22cb0d48b14a7fbfeefa113e9e7388":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc3d4a54b9e44114885a32fcf1e83154","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_654db8575f4940cb8be42f5c0fe27af2","IPY_MODEL_3b0d0cd450bf41ce89d3b75db54ffe7a","IPY_MODEL_1b83dd7f7bb847209a59fdc3a59c0f3a"]}},"cc3d4a54b9e44114885a32fcf1e83154":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"654db8575f4940cb8be42f5c0fe27af2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9a53409b3f1548839714b7b2e0090142","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffdf6ba31c77422297ff67f447c817fa"}},"3b0d0cd450bf41ce89d3b75db54ffe7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_69214746d0f547169b7d7880d4f5da93","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":406220891,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":406220891,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9f9a6c1d41b43e09bb0673958ead725"}},"1b83dd7f7bb847209a59fdc3a59c0f3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f9be4af240d441329ad63c61ff6f98f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 406M/406M [00:14&lt;00:00, 26.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c435fce47f841afb1b27f8749eecdbf"}},"9a53409b3f1548839714b7b2e0090142":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ffdf6ba31c77422297ff67f447c817fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69214746d0f547169b7d7880d4f5da93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e9f9a6c1d41b43e09bb0673958ead725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9be4af240d441329ad63c61ff6f98f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c435fce47f841afb1b27f8749eecdbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["#Ajuste fino do conjunto de dados CSTNews usando BERT Transformers by HuggingFace e Lotes Inteligentes e Validação Cruzada para todos os Folds\n","\n","Com base no modelo BERT pré-treinado realiza o ajuste fino para os dados CSTNews para classificar documentos coerentes e incoerentes.\n","\n","- Realiza o ajuste fino nos dados de CSTNEWS de Márcio Dias.\n","- Realiza a avaliação do conjunto de teste para um determinado fold(10%).\n","- A seção 2 - parametrização define os argumentos da execução.\n","\n","Notebook base: https://colab.research.google.com/drive/1KDeFAHvRFq3bY5onzj8Wgul3rRcrQNaC?usp=sharing\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n","\n","**Artigo padding dinâmico:**\n","https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e"]},{"cell_type":"markdown","metadata":{"id":"xyxb5Px3p1-e"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do notebook."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","metadata":{"id":"LOHCMMDsiyZg","executionInfo":{"status":"ok","timestamp":1634027795846,"user_tz":180,"elapsed":1129,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicioProcessamento = time.time()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2ROFCsyHu8B","executionInfo":{"status":"ok","timestamp":1634027795858,"user_tz":180,"elapsed":50,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"58a9603d-6ae0-4b62-a009-8ca740ede141"},"source":["print(\"  Tempo de início de processamento:  {:} (h:mm:ss)\".format(inicioProcessamento))"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  Tempo de início de processamento:  1634027794.5626886 (h:mm:ss)\n"]}]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.2 Tratamento de logs"]},{"cell_type":"code","metadata":{"id":"DcopxbGZqDip","executionInfo":{"status":"ok","timestamp":1634027795862,"user_tz":180,"elapsed":47,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Biblioteca de logging\n","import logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.3 Identificando o ambiente Colab"]},{"cell_type":"code","metadata":{"id":"YMiH0E3OnRa1","executionInfo":{"status":"ok","timestamp":1634027795863,"user_tz":180,"elapsed":47,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Se estiver executando no Google Colaboratory\n","import sys\n","\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = 'google.colab' in sys.modules"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rceIwWa7UmFZ"},"source":["## 1.4 Biblioteca de limpeza de tela"]},{"cell_type":"code","metadata":{"id":"PXTEvmuhUmjO","executionInfo":{"status":"ok","timestamp":1634027795864,"user_tz":180,"elapsed":48,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["from IPython.display import clear_output"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJzK1XjCnZak"},"source":["## 1.5 Conecta ao Google Drive\n","\n","É necessário existir a pasta '/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/Resultados/' para receber os resutlados do notebook."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz3RRgR-nZan","executionInfo":{"status":"ok","timestamp":1634027839488,"user_tz":180,"elapsed":43671,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"94fa42f5-f566-428d-89bd-60732993380f"},"source":["# Monta o Google Drive para esta instância de notebook.\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.6 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejzpgGrFM0-j","executionInfo":{"status":"ok","timestamp":1634027848876,"user_tz":180,"elapsed":9395,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"3717fb94-f93a-4d24-a2dc-133bd475aa35"},"source":["!pip install --upgrade wandb"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.4-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 12.8 MB/s \n","\u001b[?25hCollecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=e6bb879ec3f1eab9433063e378fcf2761a3de0c1714ac223cd412fdaa060ced2\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d93d866c628a9268d38eb0ffc67fc8c7e4bc21b7cd14a0b4da5cd9f5d6831f30\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.4 yaspin-2.1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.7 Instalação BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RfUN_KolV-f","executionInfo":{"status":"ok","timestamp":1634027855063,"user_tz":180,"elapsed":6193,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"3579fb9e-4090-4504-8a2a-10c4c1fbee5c"},"source":["!pip install -U transformers==4.5.1"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 12.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 49.9 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.5.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ne84ggOIwvlN"},"source":["## 1.8 Recupera o cohebert do Github"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HasDDV1Il1t","executionInfo":{"status":"ok","timestamp":1634027860944,"user_tz":180,"elapsed":5888,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"d9a18346-6442-4a49-8dda-292055e94a89"},"source":["!git clone https://github.com/osmarbraz/cohebert_v1.git"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cohebert_v1'...\n","remote: Enumerating objects: 4786, done.\u001b[K\n","remote: Counting objects: 100% (418/418), done.\u001b[K\n","remote: Compressing objects: 100% (270/270), done.\u001b[K\n","remote: Total 4786 (delta 283), reused 260 (delta 143), pack-reused 4368\u001b[K\n","Receiving objects: 100% (4786/4786), 28.78 MiB | 10.51 MiB/s, done.\n","Resolving deltas: 100% (3037/3037), done.\n"]}]},{"cell_type":"code","metadata":{"id":"ZYrhaS9zaWmp","executionInfo":{"status":"ok","timestamp":1634027860945,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["#Muda o diretório corrente para a pasta clonada\n","import sys\n","sys.path.append('./cohebert_v1/cohebert')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3MgI7Ldb9ce","executionInfo":{"status":"ok","timestamp":1634027860945,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Import de bibliotecas\n","from util.utilmodulo import *\n","from util.utiltempo import *\n","from util.utilarquivo import *"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.9 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtaYZmc3Vbfj","executionInfo":{"status":"ok","timestamp":1634027868158,"user_tz":180,"elapsed":7226,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"612fd3c0-d90b-4c8a-cf18-3b1671b87c98"},"source":["# Importando a biblioteca\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == '/device:GPU:0':\n","    print('Encontrei GPU em: {}'.format(device_name))\n","else:\n","    print('Dispositivo GPU não encontrado')\n","    #raise SystemError('Dispositivo GPU não encontrado')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Encontrei GPU em: /device:GPU:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos os dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla V100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla V100-SXM2-16GB(Pro)\n","- 2o Tesla P100-PCIE-16GB\n","- 3o Tesla T4\n","- 4o Tesla P4 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)\n","- 5o Tesla K80 (Não tem memória para execução 4 lotes de treino x 8 lotes de avaliação, somente 2 x 4)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrjqDO6nWa8J","executionInfo":{"status":"ok","timestamp":1634027908382,"user_tz":180,"elapsed":40236,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"f62c617a-adfd-4e1c-b9cb-cb4d3871eb15"},"source":["# Biblioteca cohebert\n","from bert.bertmodulo import *\n","\n","device = getDeviceGPU()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-10-12 08:38:12,830 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:38:27,886 : INFO : Iremos usar a GPU: Tesla K80.\n"]}]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"code","metadata":{"id":"oJ15-ylRRRdD","executionInfo":{"status":"ok","timestamp":1634027908383,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Biblioteca cohebert\n","from transformers import TrainingArguments\n","\n","# Definição dos parâmetros de Treinamento.\n","training_args = TrainingArguments(\n","    # AjusteFinoCSTNews_v1_C_SB_KF = nome do notebook\n","    # E = número de épocas\n","    # lr = taxa de aprendizagem\n","    # b = lotes de treino e avaliação\n","    # f = número do fold\n","    output_dir = 'cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f',    \n","    save_steps = 0,    \n","    seed = 42,\n","    num_train_epochs = 1, # Intervalo de valores: 2, 3, 4\n","    learning_rate = 1e-5, # Intervalo de valores: 1e-5, 2e-5, 3e-5, 4e-5, 5e-5 \n","    gradient_accumulation_steps = 1,\n","    per_device_train_batch_size = 4, \n","    per_device_eval_batch_size = 8,        \n","    evaluation_strategy = 'epoch'\n",")\n","\n","# Import de bibliotecas\n","from bert.bertarguments import ModeloArgumentosClassificacao\n","\n","# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosClassificacao(     \n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",    \n","    #pretrained_model_name_or_path = 'bert-base-multilingual-cased',\n","    do_lower_case = False,   # default True\n","    num_labels = 2,\n","    output_attentions = False,    # default False\n","    output_hidden_states = False, # default False \n","    optimizer = 'AdamW',\n","    use_wandb = False,\n","    salvar_modelo_wandb = False,\n","    salvar_modelo = False,\n","    salvar_avaliacao = True, # Salva o resultado classificações\n","    salvar_classificacao = True, # Salva o resultado da avaliação das classificações\n","    fold = 1 # Intervalo de valores: 1 a 10, É utilizado somente para logs. Use as variáveis das últimas linhas de bloco para definir o intervalo de folds a serem gerados.\n",")\n","\n","# Determina o intervalo de folds a ser avaliado\n","inicioFold = 1\n","fimFold = 10"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8cC_PRoPRl7w"},"source":["# 3 BERT"]},{"cell_type":"markdown","metadata":{"id":"e2Slpfk-dIUw"},"source":["## Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **'neuralmind/bert-base-portuguese-cased'**\n","* **'neuralmind/bert-large-portuguese-cased'**"]},{"cell_type":"code","metadata":{"id":"04TdVv56TB73","executionInfo":{"status":"ok","timestamp":1634027908383,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["# Import de bibliotecas\n","from bert.bertmodulo import *\n","\n","# Carrega o modelo e tokenizador do BERT\n","# model, tokenizer = carregaBERT(model_args)\n","\n","# O BERT será carregado para cada fold"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrKMXRNm7OI6"},"source":["# 4.Wandb\n","\n","https://wandb.ai/osmar-braz/ajustefinocstnews_v1_c_sb_kfold/table?workspace=user-osmar-braz\n"]},{"cell_type":"markdown","metadata":{"id":"ezk8hklEvPYq"},"source":["## Função de inicialização wandb"]},{"cell_type":"code","metadata":{"id":"rdsn_fhsvPwO","executionInfo":{"status":"ok","timestamp":1634027908384,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    # Importando a biblioteca.\n","    import wandb\n","\n","    #Login via linha de comando\n","    !wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd\n","\n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_v1_c_sb_kfold\", name=training_args.output_dir + str(model_args.fold))\n","\n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","    # Atualiza os parâmetros de treinamento no wandb.\n","    wandb.config.update(training_args)\n","\n","    # Registra os parämetros não literais do model_args.\n","    wandb.log({\"max_seq_len\": model_args.max_seq_len})\n","    wandb.log({\"do_lower_case\": model_args.do_lower_case})\n","    wandb.log({\"output_hidden_states\": model_args.output_hidden_states})    \n","    wandb.log({\"fold\": model_args.fold})\n","\n","    return wandb"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"av-_hPByrUCA"},"source":["# 5 Treinamento e avaliação\n","\n","Treinando e avaliando o conjunto de dados."]},{"cell_type":"markdown","metadata":{"id":"MPRD4HkL2Ymp"},"source":["## 5.1 Execução do treinamento e avaliação de todos os Folds"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ec22cb0d48b14a7fbfeefa113e9e7388","cc3d4a54b9e44114885a32fcf1e83154","654db8575f4940cb8be42f5c0fe27af2","3b0d0cd450bf41ce89d3b75db54ffe7a","1b83dd7f7bb847209a59fdc3a59c0f3a","9a53409b3f1548839714b7b2e0090142","ffdf6ba31c77422297ff67f447c817fa","69214746d0f547169b7d7880d4f5da93","e9f9a6c1d41b43e09bb0673958ead725","f9be4af240d441329ad63c61ff6f98f8","7c435fce47f841afb1b27f8749eecdbf"]},"id":"XTt9_BAS2adF","executionInfo":{"status":"ok","timestamp":1634038067790,"user_tz":180,"elapsed":10159420,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"08ef981f-866b-40a7-a08e-b7fbd4acaad3"},"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","# Biblioteca cohebert\n","from bert.bertmodulo import *\n","from conjuntodedados.dadoscstnewsclassificacaokfold import *\n","from experimento.classificacaobinaria  import *\n","from experimento.classificacaobinariakfold import *\n","\n","# Percorre todos os folds do intervalo de inicioFold até fimFold\n","for ifold in range(inicioFold, fimFold+1):\n","\n","  # Seta o parâmetro do fold\n","  model_args.fold = ifold\n","  print(\"\\nProcessamendo do fold: {}\".format(model_args.fold))\n","  \n","  # Marca o tempo de início do processamento\n","  inicioProcessamentof = time.time()\n","\n","  print(\"  Tempo de início de processamento fold:  {:} (h:mm:ss)\".format(formataTempo(inicioProcessamentof)))\n","\n","  # Carrega o modelo e tokenizador do BERT\n","  model, tokenizer = carregaBERT(model_args)\n","\n","  # Inicializa o wandb para registro\n","  wandb = inicializacaoWandb()\n","\n","  # Função de carregamento dos dados de um fold\n","  dfdados_train, dfdados_test = getConjuntoDeDadosClassificacaoFold(model_args, tokenizer, ORIGEM=None)\n","\n","  # Pega as listas de documentos de treino e seus rótulos.\n","  documentos_treino = dfdados_train.documento.values\n","  classes_treino = dfdados_train.classe.values\n","  documentoids_treino = dfdados_train.id.values\n","\n","  # Pega as listas de documentos teste e seus rótulos.\n","  documentos_teste = dfdados_test.documento.values\n","  classes_teste = dfdados_test.classe.values\n","  documentoids_teste = dfdados_test.id.values\n","\n","  # Mostra o resultado dos dados carregados.\n","  print(\"Total do conjunto de dados          : {}.\".format(len(documentos_treino) + len(documentos_teste)))\n","  print(\"Total do conjunto de dados de treino: {}.\".format(len(documentos_treino)))\n","  print(\"Total do conjunto de dados de teste : {}.\".format(len(documentos_teste)))\n","\n","  #################  Treinamento\n","\n","  # Registra o tempo inicial.\n","  treinamento_t0 = time.time()\n","\n","  # Realiza o treinamento.\n","  model = realizaTreinamento(model_args, training_args, model, tokenizer, documentos_treino, classes_treino, documentoids_treino, wandb)\n","  \n","  # Medida de quanto tempo levou a execução do treinamento.\n","  treinamento_total = formataTempo(time.time() - treinamento_t0)\n","\n","  print(\"  Tempo total treinamento       : {:}\".format(treinamento_total))\n","  \n","  #################  Treinamento\n","\n","  ################# Avaliação\n","\n","  # Registra o tempo inicial.\n","  avaliacao_t0 = time.time()\n","\n","  # Realiza a avaliação do modelo.\n","  media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(model_args, training_args, model, tokenizer, documentos_teste, classes_teste, documentoids_teste, wandb)\n","\n","  print('Avaliação loss: {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}'.format( \n","        media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))      \n","    \n","  print(\"Acurácia do fold {}        : {:.8f}\".format(model_args.fold, acc))  \n","\n","  # Medida de quanto tempo levou a execução do treinamento e avaliação\n","  avaliacao_total = formataTempo(time.time() - avaliacao_t0)\n","\n","  print(\"Tempo gasto na avaliação  : {:}\".format(avaliacao_total))\n","\n","  ################# Avaliação\n","\n","  # Salva o resultado da classificação  \n","  # Diretório para salvar o arquivo de classificação.\n","  DIRETORIO_CLASSIFICACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/\"\n","  salvaResultadoClassificacao(model_args, training_args, DIRETORIO_CLASSIFICACAO, lista_resultado_avaliacao)\n","  \n","  # Salva o resultado da avaliação\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/\"  \n","  salvaResultadoAvaliacao(model_args, training_args, DIRETORIO_AVALIACAO, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, treinamento_total)\n","  \n","  # Apaga os dados\n","  del dfdados_train\n","  del dfdados_test\n","  del documentos_treino\n","  del classes_treino\n","  del documentoids_treino\n","  del documentos_teste\n","  del classes_teste\n","  del documentoids_teste\n","  del lista_resultado_avaliacao  \n","  del model\n","\n","  # Pega o tempo atual menos o tempo do início do processamento.\n","  finalProcessamentof = time.time()\n","  tempoTotalProcessamentof = formataTempo(finalProcessamentof - inicioProcessamentof)\n","\n","  print(\"\")\n","  print(\"Tempo processamento fold: {:} (h:mm:ss)\".format(tempoTotalProcessamentof))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processamendo do fold: 1\n","  Tempo de início de processamento fold:  18912 days, 8:38:29 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:38:29,290 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec22cb0d48b14a7fbfeefa113e9e7388","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:38:48,756 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e21765850e7e495f8e4e1885081ffe1a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:38:49,147 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 08:38:49,205 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 08:38:49,206 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 08:38:52,538 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:38:52,540 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 08:38:52,667 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 08:38:52,674 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 08:38:52,712 : INFO : Copiando do CSTNews do checkout do Github\n","2021-10-12 08:38:52,714 : INFO : Diretório para receber os dados criado: /content/validacao_kfold.\n","2021-10-12 08:38:53,137 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f1.csv.\n","2021-10-12 08:38:53,139 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f1.csv.\n","2021-10-12 08:38:53,230 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 08:38:53,246 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 08:39:24,588 : INFO : NumExpr defaulting to 2 threads.\n","2021-10-12 08:39:24,611 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 08:39:24,613 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 08:39:24,657 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 08:39:28,108 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 08:39:28,109 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 08:39:28,132 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 08:39:28,139 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:39:28,140 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 08:39:28,144 : INFO : Realizando Treinamento fold: 1\n","2021-10-12 08:39:28,156 : INFO : Otimizador carregado.\n","2021-10-12 08:39:28,157 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"177918560d7a4a15b8f7d01c53eb89b9","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:39:28,206 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 08:39:59,346 : INFO : Tokenização concluída.\n","2021-10-12 08:39:59,347 : INFO :      8,964 amostras.\n","2021-10-12 08:39:59,362 : INFO :      8,964 amostras após classificação.\n","2021-10-12 08:39:59,364 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 08:39:59,383 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"facc9e7b134245d9913ba0b81130e421","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:54:46,038 : INFO :   Média perda(loss) do treinamento da época : 0.31837873.\n","2021-10-12 08:54:46,048 : INFO :   Tempo de treinamento da época             : 0:14:46.\n","2021-10-12 08:54:46,050 : INFO :   Tempo parcial do treinamento              : 0:15:18 (h:mm:ss).\n","2021-10-12 08:54:46,063 : INFO :   Média perda(loss) treinamento : 0.31837873.\n","2021-10-12 08:54:46,074 : INFO : Treinamento completo!\n","2021-10-12 08:54:46,078 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:54:46,080 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 08:54:46,083 : INFO : Realizando Avaliação fold: 1.\n","2021-10-12 08:54:46,085 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 08:54:46,088 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:18\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:54:49,536 : INFO : Tokenização concluída.\n","2021-10-12 08:54:49,538 : INFO :        996 amostras.\n","2021-10-12 08:54:49,543 : INFO :        996 amostras após classificação.\n","2021-10-12 08:54:49,546 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 08:54:49,550 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5110c8d808104f19aa5a6d5281bf655a","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.17629199; Acc: 0.96084337; Rec: 1.00000000; Pre: 0.92737430, F1:0.96231884, vp: 498; vn: 459; fp:  39; fn:   0\n","Acurácia do fold 1        : 0.96084337\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:55:20,974 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 08:55:25,407 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f1_BERTimbau_base.csv.\n","2021-10-12 08:55:25,947 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 08:55:29,159 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f1_BERTimbau_base.csv.\n","2021-10-12 08:55:29,673 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:17:01 (h:mm:ss)\n","\n","Processamendo do fold: 2\n","  Tempo de início de processamento fold:  18912 days, 8:55:30 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:55:30,243 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8063fe726ac4ec1b01ddcb9e7ea9ee0","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:55:51,101 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8387f8cbe273475fa23fc40c681879dc","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:55:51,478 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 08:55:51,542 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 08:55:51,543 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 08:55:54,561 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:55:54,565 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 08:55:54,670 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 08:55:54,678 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 08:55:54,720 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f2.csv.\n","2021-10-12 08:55:54,724 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f2.csv.\n","2021-10-12 08:55:54,803 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 08:55:54,820 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 08:56:25,888 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 08:56:25,890 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 08:56:25,926 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 08:56:29,358 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 08:56:29,360 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 08:56:29,381 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 08:56:29,384 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 08:56:29,389 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 08:56:29,391 : INFO : Realizando Treinamento fold: 2\n","2021-10-12 08:56:29,396 : INFO : Otimizador carregado.\n","2021-10-12 08:56:29,398 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a4c91e7491d46e3bc74e25e4c741225","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 08:56:30,082 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 08:57:01,288 : INFO : Tokenização concluída.\n","2021-10-12 08:57:01,290 : INFO :      8,964 amostras.\n","2021-10-12 08:57:01,310 : INFO :      8,964 amostras após classificação.\n","2021-10-12 08:57:01,311 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 08:57:01,330 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b5431722e0c4ee687dec99d9c76b1a6","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:11:47,856 : INFO :   Média perda(loss) do treinamento da época : 0.33769834.\n","2021-10-12 09:11:47,865 : INFO :   Tempo de treinamento da época             : 0:14:46.\n","2021-10-12 09:11:47,868 : INFO :   Tempo parcial do treinamento              : 0:15:18 (h:mm:ss).\n","2021-10-12 09:11:47,883 : INFO :   Média perda(loss) treinamento : 0.33769834.\n","2021-10-12 09:11:47,901 : INFO : Treinamento completo!\n","2021-10-12 09:11:47,905 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:11:47,908 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:11:47,910 : INFO : Realizando Avaliação fold: 2.\n","2021-10-12 09:11:47,913 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 09:11:47,916 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:19\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:11:51,404 : INFO : Tokenização concluída.\n","2021-10-12 09:11:51,410 : INFO :        996 amostras.\n","2021-10-12 09:11:51,412 : INFO :        996 amostras após classificação.\n","2021-10-12 09:11:51,418 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 09:11:51,420 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed28dec2ae894f479160a18b6d5f3f99","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:12:20,756 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 09:12:20,765 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f2_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.22517974; Acc: 0.95180723; Rec: 0.98795181; Pre: 0.92134831, F1:0.95348837, vp: 492; vn: 456; fp:  42; fn:   6\n","Acurácia do fold 2        : 0.95180723\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:12:21,424 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 09:12:21,430 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f2_BERTimbau_base.csv.\n","2021-10-12 09:12:21,928 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:52 (h:mm:ss)\n","\n","Processamendo do fold: 3\n","  Tempo de início de processamento fold:  18912 days, 9:12:22 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:12:22,529 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09019c8da9544e23b1f01b977f78afed","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:12:43,943 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5362004d8cb74880baa2e4c1bb975e1a","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:12:44,333 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 09:12:44,402 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 09:12:44,404 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 09:12:47,605 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:12:47,607 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:12:47,711 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 09:12:47,720 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 09:12:47,765 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f3.csv.\n","2021-10-12 09:12:47,767 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f3.csv.\n","2021-10-12 09:12:47,849 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 09:12:47,867 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 09:13:18,904 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 09:13:18,905 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 09:13:18,943 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:13:22,417 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 09:13:22,419 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 09:13:22,441 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:13:22,444 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:13:22,448 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:13:22,452 : INFO : Realizando Treinamento fold: 3\n","2021-10-12 09:13:22,461 : INFO : Otimizador carregado.\n","2021-10-12 09:13:22,462 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ad9f35367a4cff9068cad481048b23","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:13:23,116 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 09:13:54,337 : INFO : Tokenização concluída.\n","2021-10-12 09:13:54,338 : INFO :      8,964 amostras.\n","2021-10-12 09:13:54,588 : INFO :      8,964 amostras após classificação.\n","2021-10-12 09:13:54,595 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 09:13:54,612 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d085e79361b64786a475c5d338aa87b8","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:28:40,118 : INFO :   Média perda(loss) do treinamento da época : 0.34449146.\n","2021-10-12 09:28:40,120 : INFO :   Tempo de treinamento da época             : 0:14:45.\n","2021-10-12 09:28:40,126 : INFO :   Tempo parcial do treinamento              : 0:15:18 (h:mm:ss).\n","2021-10-12 09:28:40,146 : INFO :   Média perda(loss) treinamento : 0.34449146.\n","2021-10-12 09:28:40,149 : INFO : Treinamento completo!\n","2021-10-12 09:28:40,152 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:28:40,155 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:28:40,157 : INFO : Realizando Avaliação fold: 3.\n","2021-10-12 09:28:40,160 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 09:28:40,163 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:18\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:28:43,700 : INFO : Tokenização concluída.\n","2021-10-12 09:28:43,701 : INFO :        996 amostras.\n","2021-10-12 09:28:43,704 : INFO :        996 amostras após classificação.\n","2021-10-12 09:28:43,707 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 09:28:43,712 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aacbd36655b94655b09a551dcdcc7b2e","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:29:13,300 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 09:29:13,317 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f3_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.22158452; Acc: 0.94678715; Rec: 1.00000000; Pre: 0.90381125, F1:0.94947569, vp: 498; vn: 445; fp:  53; fn:   0\n","Acurácia do fold 3        : 0.94678715\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:29:13,775 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 09:29:13,777 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f3_BERTimbau_base.csv.\n","2021-10-12 09:29:14,273 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:52 (h:mm:ss)\n","\n","Processamendo do fold: 4\n","  Tempo de início de processamento fold:  18912 days, 9:29:14 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:29:14,875 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a734491b0984a1fb16dcf6298df5188","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:29:35,976 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f5db33f4a514b2f91d503719ccf430d","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:29:36,356 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 09:29:36,421 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 09:29:36,423 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 09:29:39,429 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:29:39,431 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:29:39,540 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 09:29:39,547 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 09:29:39,586 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f4.csv.\n","2021-10-12 09:29:39,588 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f4.csv.\n","2021-10-12 09:29:39,666 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 09:29:39,685 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 09:30:10,753 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 09:30:10,763 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 09:30:10,797 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:30:14,238 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 09:30:14,241 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 09:30:14,262 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:30:14,266 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:30:14,269 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:30:14,272 : INFO : Realizando Treinamento fold: 4\n","2021-10-12 09:30:14,278 : INFO : Otimizador carregado.\n","2021-10-12 09:30:14,280 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c22841c972ef46b29136d89848214873","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:30:14,954 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 09:30:46,002 : INFO : Tokenização concluída.\n","2021-10-12 09:30:46,004 : INFO :      8,964 amostras.\n","2021-10-12 09:30:46,024 : INFO :      8,964 amostras após classificação.\n","2021-10-12 09:30:46,025 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 09:30:46,047 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b052ac92ade14741902d3bc5fc605a4f","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:45:32,822 : INFO :   Média perda(loss) do treinamento da época : 0.34913546.\n","2021-10-12 09:45:32,833 : INFO :   Tempo de treinamento da época             : 0:14:46.\n","2021-10-12 09:45:32,842 : INFO :   Tempo parcial do treinamento              : 0:15:19 (h:mm:ss).\n","2021-10-12 09:45:32,858 : INFO :   Média perda(loss) treinamento : 0.34913546.\n","2021-10-12 09:45:32,864 : INFO : Treinamento completo!\n","2021-10-12 09:45:32,869 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:45:32,872 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:45:32,873 : INFO : Realizando Avaliação fold: 4.\n","2021-10-12 09:45:32,875 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 09:45:32,877 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:19\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:45:36,358 : INFO : Tokenização concluída.\n","2021-10-12 09:45:36,360 : INFO :        996 amostras.\n","2021-10-12 09:45:36,362 : INFO :        996 amostras após classificação.\n","2021-10-12 09:45:36,368 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 09:45:36,373 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ade47f4f0038403ebde543ec2e52f69d","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:46:05,856 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 09:46:05,870 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f4_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.23268313; Acc: 0.94176707; Rec: 0.99196787; Pre: 0.90145985, F1:0.94455067, vp: 494; vn: 444; fp:  54; fn:   4\n","Acurácia do fold 4        : 0.94176707\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:46:06,362 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 09:46:06,376 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f4_BERTimbau_base.csv.\n","2021-10-12 09:46:06,868 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:53 (h:mm:ss)\n","\n","Processamendo do fold: 5\n","  Tempo de início de processamento fold:  18912 days, 9:46:07 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:46:07,444 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6749c8da57543c5a6ee26d9156ba395","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:46:27,971 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db69592b88514e1ebfb6f0ccbc58c228","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:46:28,349 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 09:46:28,422 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 09:46:28,424 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 09:46:31,430 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:46:31,433 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:46:31,533 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 09:46:31,540 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 09:46:31,581 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f5.csv.\n","2021-10-12 09:46:31,582 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f5.csv.\n","2021-10-12 09:46:31,660 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 09:46:31,677 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 09:47:02,888 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 09:47:02,890 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 09:47:02,944 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:47:06,435 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 09:47:06,436 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 09:47:06,457 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 09:47:06,460 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 09:47:06,461 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 09:47:06,464 : INFO : Realizando Treinamento fold: 5\n","2021-10-12 09:47:06,468 : INFO : Otimizador carregado.\n","2021-10-12 09:47:06,470 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb099a5c6aed4b4c988457d082a8a8bf","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 09:47:07,124 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 09:47:38,232 : INFO : Tokenização concluída.\n","2021-10-12 09:47:38,234 : INFO :      8,964 amostras.\n","2021-10-12 09:47:38,252 : INFO :      8,964 amostras após classificação.\n","2021-10-12 09:47:38,255 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 09:47:38,279 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9d244a10883474090afc03550c7a90e","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:02:28,602 : INFO :   Média perda(loss) do treinamento da época : 0.38959993.\n","2021-10-12 10:02:28,607 : INFO :   Tempo de treinamento da época             : 0:14:50.\n","2021-10-12 10:02:28,609 : INFO :   Tempo parcial do treinamento              : 0:15:22 (h:mm:ss).\n","2021-10-12 10:02:28,627 : INFO :   Média perda(loss) treinamento : 0.38959993.\n","2021-10-12 10:02:28,630 : INFO : Treinamento completo!\n","2021-10-12 10:02:28,634 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:02:28,636 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:02:28,638 : INFO : Realizando Avaliação fold: 5.\n","2021-10-12 10:02:28,640 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 10:02:28,642 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:22\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:02:32,162 : INFO : Tokenização concluída.\n","2021-10-12 10:02:32,165 : INFO :        996 amostras.\n","2021-10-12 10:02:32,175 : INFO :        996 amostras após classificação.\n","2021-10-12 10:02:32,176 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 10:02:32,181 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4780086e824c4c7aa7341e7898f4ccf7","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:03:01,800 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 10:03:01,814 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f5_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.30154023; Acc: 0.92771084; Rec: 1.00000000; Pre: 0.87368421, F1:0.93258427, vp: 498; vn: 426; fp:  72; fn:   0\n","Acurácia do fold 5        : 0.92771084\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:03:02,325 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 10:03:02,341 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f5_BERTimbau_base.csv.\n","2021-10-12 10:03:02,928 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:56 (h:mm:ss)\n","\n","Processamendo do fold: 6\n","  Tempo de início de processamento fold:  18912 days, 10:03:03 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:03:03,513 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49d6c9d0570a4cf0a5a55e1030b59e4b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:03:24,313 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47ecef07ca064138ac4bae58601e2a79","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:03:24,698 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 10:03:24,769 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 10:03:24,770 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 10:03:27,934 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:03:27,938 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:03:28,041 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 10:03:28,050 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 10:03:28,095 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f6.csv.\n","2021-10-12 10:03:28,097 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f6.csv.\n","2021-10-12 10:03:28,182 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 10:03:28,201 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 10:03:59,548 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 10:03:59,550 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 10:03:59,589 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:04:03,097 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 10:04:03,103 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 10:04:03,122 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:04:03,126 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:04:03,128 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:04:03,136 : INFO : Realizando Treinamento fold: 6\n","2021-10-12 10:04:03,139 : INFO : Otimizador carregado.\n","2021-10-12 10:04:03,146 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae95e6a22c774c429df9a4bcdcf19c23","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:04:03,816 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 10:04:35,038 : INFO : Tokenização concluída.\n","2021-10-12 10:04:35,040 : INFO :      8,964 amostras.\n","2021-10-12 10:04:35,071 : INFO :      8,964 amostras após classificação.\n","2021-10-12 10:04:35,072 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 10:04:35,096 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48d045baa71a4c68ab5926205be521b7","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:19:25,632 : INFO :   Média perda(loss) do treinamento da época : 0.34882351.\n","2021-10-12 10:19:25,636 : INFO :   Tempo de treinamento da época             : 0:14:50.\n","2021-10-12 10:19:25,642 : INFO :   Tempo parcial do treinamento              : 0:15:22 (h:mm:ss).\n","2021-10-12 10:19:25,662 : INFO :   Média perda(loss) treinamento : 0.34882351.\n","2021-10-12 10:19:25,671 : INFO : Treinamento completo!\n","2021-10-12 10:19:25,675 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:19:25,677 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:19:25,679 : INFO : Realizando Avaliação fold: 6.\n","2021-10-12 10:19:25,685 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 10:19:25,695 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:23\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:19:29,214 : INFO : Tokenização concluída.\n","2021-10-12 10:19:29,215 : INFO :        996 amostras.\n","2021-10-12 10:19:29,217 : INFO :        996 amostras após classificação.\n","2021-10-12 10:19:29,223 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 10:19:29,230 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f51d27ea4324e898d268790b7068949","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:19:58,841 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 10:19:58,860 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f6_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.28072817; Acc: 0.94176707; Rec: 0.98594378; Pre: 0.90590406, F1:0.94423077, vp: 491; vn: 447; fp:  51; fn:   7\n","Acurácia do fold 6        : 0.94176707\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:19:59,335 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 10:19:59,343 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f6_BERTimbau_base.csv.\n","2021-10-12 10:19:59,799 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:57 (h:mm:ss)\n","\n","Processamendo do fold: 7\n","  Tempo de início de processamento fold:  18912 days, 10:20:00 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:20:00,369 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21042558fbbd4310b377949e79c48232","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:20:33,106 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d8d63a5a99c45d59dba4ba4abf9c8d2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:20:33,493 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 10:20:33,616 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 10:20:33,619 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 10:20:36,858 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:20:36,862 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:20:36,963 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 10:20:36,969 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 10:20:37,021 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f7.csv.\n","2021-10-12 10:20:37,023 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f7.csv.\n","2021-10-12 10:20:37,105 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 10:20:37,125 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 10:21:08,046 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 10:21:08,047 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 10:21:08,087 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:21:11,573 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 10:21:11,576 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 10:21:11,599 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:21:11,607 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:21:11,611 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:21:11,617 : INFO : Realizando Treinamento fold: 7\n","2021-10-12 10:21:11,625 : INFO : Otimizador carregado.\n","2021-10-12 10:21:11,626 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f06361c2ac245a9a93977836111bbd3","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:21:12,301 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 10:21:43,215 : INFO : Tokenização concluída.\n","2021-10-12 10:21:43,217 : INFO :      8,964 amostras.\n","2021-10-12 10:21:43,242 : INFO :      8,964 amostras após classificação.\n","2021-10-12 10:21:43,244 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 10:21:43,266 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8024538defc541338ad4fb2efeec970a","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:36:31,384 : INFO :   Média perda(loss) do treinamento da época : 0.34888404.\n","2021-10-12 10:36:31,393 : INFO :   Tempo de treinamento da época             : 0:14:48.\n","2021-10-12 10:36:31,396 : INFO :   Tempo parcial do treinamento              : 0:15:20 (h:mm:ss).\n","2021-10-12 10:36:31,418 : INFO :   Média perda(loss) treinamento : 0.34888404.\n","2021-10-12 10:36:31,426 : INFO : Treinamento completo!\n","2021-10-12 10:36:31,432 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:36:31,435 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:36:31,439 : INFO : Realizando Avaliação fold: 7.\n","2021-10-12 10:36:31,441 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 10:36:31,445 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:20\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:36:35,035 : INFO : Tokenização concluída.\n","2021-10-12 10:36:35,037 : INFO :        996 amostras.\n","2021-10-12 10:36:35,047 : INFO :        996 amostras após classificação.\n","2021-10-12 10:36:35,049 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 10:36:35,056 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a3483d7b06a4afdadb61851a0d5fe0c","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:37:05,115 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 10:37:05,134 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f7_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.30045545; Acc: 0.93273092; Rec: 0.99397590; Pre: 0.88550984, F1:0.93661306, vp: 495; vn: 434; fp:  64; fn:   3\n","Acurácia do fold 7        : 0.93273092\n","Tempo gasto na avaliação  : 0:00:34\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:37:05,652 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 10:37:05,663 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f7_BERTimbau_base.csv.\n","2021-10-12 10:37:06,124 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:17:06 (h:mm:ss)\n","\n","Processamendo do fold: 8\n","  Tempo de início de processamento fold:  18912 days, 10:37:06 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:37:06,701 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0743c8d2ff7449aba86ae47c104dff2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:37:27,960 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2471822001249ad8debe55692262bc7","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:37:28,347 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 10:37:28,414 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 10:37:28,416 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 10:37:31,542 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:37:31,547 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:37:31,645 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 10:37:31,654 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 10:37:31,693 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f8.csv.\n","2021-10-12 10:37:31,696 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f8.csv.\n","2021-10-12 10:37:31,775 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 10:37:31,798 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 10:38:03,196 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 10:38:03,198 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 10:38:03,241 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:38:06,746 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 10:38:06,748 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 10:38:06,771 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:38:06,774 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:38:06,776 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:38:06,778 : INFO : Realizando Treinamento fold: 8\n","2021-10-12 10:38:06,785 : INFO : Otimizador carregado.\n","2021-10-12 10:38:06,788 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de1c9d957f24485098e47d8fb95a28c8","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:38:07,440 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 10:38:38,721 : INFO : Tokenização concluída.\n","2021-10-12 10:38:38,722 : INFO :      8,964 amostras.\n","2021-10-12 10:38:38,741 : INFO :      8,964 amostras após classificação.\n","2021-10-12 10:38:38,747 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 10:38:38,770 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82793a508c2b4d92b786c1e3538e0e78","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:53:26,638 : INFO :   Média perda(loss) do treinamento da época : 0.35429034.\n","2021-10-12 10:53:26,647 : INFO :   Tempo de treinamento da época             : 0:14:47.\n","2021-10-12 10:53:26,653 : INFO :   Tempo parcial do treinamento              : 0:15:20 (h:mm:ss).\n","2021-10-12 10:53:26,668 : INFO :   Média perda(loss) treinamento : 0.35429034.\n","2021-10-12 10:53:26,671 : INFO : Treinamento completo!\n","2021-10-12 10:53:26,679 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:53:26,682 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:53:26,684 : INFO : Realizando Avaliação fold: 8.\n","2021-10-12 10:53:26,690 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 10:53:26,699 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:20\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:53:30,176 : INFO : Tokenização concluída.\n","2021-10-12 10:53:30,180 : INFO :        996 amostras.\n","2021-10-12 10:53:30,184 : INFO :        996 amostras após classificação.\n","2021-10-12 10:53:30,187 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 10:53:30,191 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6579c12889fa413987a422f9b9ec866f","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:53:59,762 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 10:53:59,785 : INFO : Atualizando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f8_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.32802413; Acc: 0.92269076; Rec: 0.95582329; Pre: 0.89642185, F1:0.92517007, vp: 476; vn: 443; fp:  55; fn:  22\n","Acurácia do fold 8        : 0.92269076\n","Tempo gasto na avaliação  : 0:00:33\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:54:00,332 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 10:54:00,340 : INFO : Atualizando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f8_BERTimbau_base.csv.\n","2021-10-12 10:54:00,778 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tempo processamento fold: 0:16:55 (h:mm:ss)\n","\n","Processamendo do fold: 9\n","  Tempo de início de processamento fold:  18912 days, 10:54:01 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:54:01,351 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e422fd1237b0429494bce8ca38fc379c","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:54:21,340 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04e22280bf8045aaa4cde3a76b9750d9","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:54:21,716 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 10:54:21,792 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 10:54:21,794 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 10:54:24,940 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:54:24,944 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:54:25,057 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 10:54:25,067 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 10:54:25,113 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f9.csv.\n","2021-10-12 10:54:25,117 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f9.csv.\n","2021-10-12 10:54:25,199 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 10:54:25,218 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 10:54:56,202 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 10:54:56,204 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 10:54:56,244 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:54:59,710 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 10:54:59,717 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 10:54:59,736 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 10:54:59,739 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 10:54:59,743 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 10:54:59,749 : INFO : Realizando Treinamento fold: 9\n","2021-10-12 10:54:59,756 : INFO : Otimizador carregado.\n","2021-10-12 10:54:59,758 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2c96b734a164a21bb5032e9d8c1ff8c","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 10:55:00,424 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 10:55:31,324 : INFO : Tokenização concluída.\n","2021-10-12 10:55:31,326 : INFO :      8,964 amostras.\n","2021-10-12 10:55:31,348 : INFO :      8,964 amostras após classificação.\n","2021-10-12 10:55:31,349 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 10:55:31,379 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2466246e3bd48af9b51a101a5c9ed9a","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:10:20,144 : INFO :   Média perda(loss) do treinamento da época : 0.34691441.\n","2021-10-12 11:10:20,150 : INFO :   Tempo de treinamento da época             : 0:14:48.\n","2021-10-12 11:10:20,154 : INFO :   Tempo parcial do treinamento              : 0:15:20 (h:mm:ss).\n","2021-10-12 11:10:20,175 : INFO :   Média perda(loss) treinamento : 0.34691441.\n","2021-10-12 11:10:20,179 : INFO : Treinamento completo!\n","2021-10-12 11:10:20,185 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 11:10:20,188 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 11:10:20,190 : INFO : Realizando Avaliação fold: 9.\n","2021-10-12 11:10:20,191 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 11:10:20,193 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:20\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:10:23,734 : INFO : Tokenização concluída.\n","2021-10-12 11:10:23,737 : INFO :        996 amostras.\n","2021-10-12 11:10:23,740 : INFO :        996 amostras após classificação.\n","2021-10-12 11:10:23,745 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 11:10:23,758 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e125c66e17f7410b8744fac44ea407b1","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:10:53,499 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 11:10:53,520 : INFO : Criando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f9_BERTimbau_base.csv.\n","2021-10-12 11:10:53,539 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 11:10:53,546 : INFO : Criando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f9_BERTimbau_base.csv.\n","2021-10-12 11:10:53,561 : INFO : Apagando diretório existente do modelo!\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.24035900; Acc: 0.94578313; Rec: 0.99598394; Pre: 0.90510949, F1:0.94837476, vp: 496; vn: 446; fp:  52; fn:   2\n","Acurácia do fold 9        : 0.94578313\n","Tempo gasto na avaliação  : 0:00:33\n","\n","Tempo processamento fold: 0:16:53 (h:mm:ss)\n","\n","Processamendo do fold: 10\n","  Tempo de início de processamento fold:  18912 days, 11:10:54 (h:mm:ss)\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:10:54,126 : INFO : Download do arquivo: bert-base-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"463fc58fe1c0497b9c4a9e71a7d99e21","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/406M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:11:15,051 : INFO : Download do arquivo: cohebert_v1/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c55f97496b1b4ac6a988c1390ac8b626","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:11:15,433 : INFO : Diretório cohebert_v1/modeloBERT do modelo BERT pronta!\n","2021-10-12 11:11:15,506 : INFO : Usando modelo BERT pré-treinado.\n","2021-10-12 11:11:15,508 : INFO : Carregando o modelo BERT do diretório cohebert_v1/modeloBERT para classificação.\n","Some weights of the model checkpoint at cohebert_v1/modeloBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cohebert_v1/modeloBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","2021-10-12 11:11:18,692 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 11:11:18,705 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 11:11:18,819 : INFO : Pytorch rodando o modelo na GPU.\n","2021-10-12 11:11:18,828 : INFO : Carregando o tokenizador BERT do diretório cohebert_v1/modeloBERT.\n","2021-10-12 11:11:18,867 : INFO : Carregando arquivo de treino: /content/validacao_kfold/cstnews_md_train_f10.csv.\n","2021-10-12 11:11:18,868 : INFO : Carregando arquivo de teste: /content/validacao_kfold/cstnews_md_test_f10.csv.\n","2021-10-12 11:11:19,134 : INFO : Qtde de dados de treino: 8964.\n","2021-10-12 11:11:19,218 : INFO : Qtde de dados de teste: 996.\n","2021-10-12 11:11:50,377 : INFO : Quantidade de dados anterior: 8964.\n","2021-10-12 11:11:50,378 : INFO : Nova quantidade de dados    : 8964.\n","2021-10-12 11:11:50,423 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 11:11:53,906 : INFO : Quantidade de dados anterior: 996.\n","2021-10-12 11:11:53,910 : INFO : Nova quantidade de dados    : 996.\n","2021-10-12 11:11:53,933 : INFO : Quantidade de registros removidos: 0.\n","2021-10-12 11:11:53,936 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 11:11:53,937 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 11:11:53,939 : INFO : Realizando Treinamento fold: 10\n","2021-10-12 11:11:53,945 : INFO : Otimizador carregado.\n","2021-10-12 11:11:53,948 : INFO : Total de etapas do agendador: 8964.\n"]},{"output_type":"stream","name":"stdout","text":["Total do conjunto de dados          : 9960.\n","Total do conjunto de dados de treino: 8964.\n","Total do conjunto de dados de teste : 996.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b7bdf5f8c344f1b9ca39fc8c1181d8d","version_minor":0,"version_major":2},"text/plain":["Épocas:   0%|          | 0/1 [00:00<?, ?épocas/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:11:54,651 : INFO : Tokenizando 8,964 amostra.\n","2021-10-12 11:12:25,773 : INFO : Tokenização concluída.\n","2021-10-12 11:12:25,774 : INFO :      8,964 amostras.\n","2021-10-12 11:12:26,353 : INFO :      8,964 amostras após classificação.\n","2021-10-12 11:12:26,355 : INFO : Criando lotes de tamanho 4.\n","2021-10-12 11:12:26,379 : INFO : Lote criado - Selecionado 2,241 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"951cf1c21d394464b3db82eea01183d2","version_minor":0,"version_major":2},"text/plain":["Epoca 1:   0%|          | 0/2241 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:27:13,304 : INFO :   Média perda(loss) do treinamento da época : 0.35850091.\n","2021-10-12 11:27:13,313 : INFO :   Tempo de treinamento da época             : 0:14:47.\n","2021-10-12 11:27:13,316 : INFO :   Tempo parcial do treinamento              : 0:15:19 (h:mm:ss).\n","2021-10-12 11:27:13,335 : INFO :   Média perda(loss) treinamento : 0.35850091.\n","2021-10-12 11:27:13,338 : INFO : Treinamento completo!\n","2021-10-12 11:27:13,343 : INFO : Existem 1 GPU(s) disponíveis.\n","2021-10-12 11:27:13,346 : INFO : Iremos usar a GPU: Tesla K80.\n","2021-10-12 11:27:13,348 : INFO : Realizando Avaliação fold: 10.\n","2021-10-12 11:27:13,350 : INFO : Predizendo rótulos para 996 documentos de teste.\n","2021-10-12 11:27:13,352 : INFO : Tokenizando 996 amostra.\n"]},{"output_type":"stream","name":"stdout","text":["  Tempo total treinamento       : 0:15:19\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:27:16,922 : INFO : Tokenização concluída.\n","2021-10-12 11:27:16,926 : INFO :        996 amostras.\n","2021-10-12 11:27:16,930 : INFO :        996 amostras após classificação.\n","2021-10-12 11:27:16,932 : INFO : Criando lotes de tamanho 8.\n","2021-10-12 11:27:16,936 : INFO : Lote criado - Selecionado 125 lotes.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"402500242f734dcd8d826aea71f19d89","version_minor":0,"version_major":2},"text/plain":["Lotes :   0%|          | 0/125 [00:00<?, ?lotes/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2021-10-12 11:27:46,840 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/.\n","2021-10-12 11:27:46,854 : INFO : Criando arquivo classificação: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Classificacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f10_BERTimbau_base.csv.\n","2021-10-12 11:27:46,882 : INFO : Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/.\n","2021-10-12 11:27:46,890 : INFO : Criando arquivo resultado: /content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f10_BERTimbau_base.csv.\n"]},{"output_type":"stream","name":"stdout","text":["Avaliação loss: 0.16585237; Acc: 0.95983936; Rec: 0.99196787; Pre: 0.93207547, F1:0.96108949, vp: 494; vn: 462; fp:  36; fn:   4\n","Acurácia do fold 10        : 0.95983936\n","Tempo gasto na avaliação  : 0:00:33\n","\n","Tempo processamento fold: 0:16:53 (h:mm:ss)\n"]}]},{"cell_type":"markdown","metadata":{"id":"bUskOwzJmpDB"},"source":["### Carrega e calcula a acurácia médias das execuções\n"]},{"cell_type":"code","metadata":{"id":"BahqkebDFOye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634038067791,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"fc04cf57-e137-41cb-ec97-f70cd8c84d69"},"source":["# Biblioteca cohebert\n","from experimento.classificacaobinariakfold import *\n","\n","# Diretório para salvar o arquivo.\n","DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/Avaliacao/\"\n","\n","carregaResultadoAvaliacao(model_args, training_args, DIRETORIO_AVALIACAO)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-10-12 11:27:46,923 : INFO : Média dos arquivos: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f X _base.\n","2021-10-12 11:27:46,941 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f1_BERTimbau_base, Data: 18/09/2021 00:21, Tempo: 0:14:20, QtdeTeste: 996, Acc: 0.95080321, Rec: 0.97389558, Pre: 0.93090211, F1:0.95191364, vp:  485; vn:  462; fp:   36; fn:   13\n","2021-10-12 11:27:46,944 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f1_BERTimbau_base, Data: 21/09/2021 02:16, Tempo: 0:15:04, QtdeTeste: 996, Acc: 0.92771084, Rec: 0.98192771, Pre: 0.88586957, F1:0.93142857, vp:  489; vn:  435; fp:   63; fn:    9\n","2021-10-12 11:27:46,946 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f1_BERTimbau_base, Data: 12/10/2021 08:55, Tempo: 0:15:18, QtdeTeste: 996, Acc: 0.96084337, Rec: 1.00000000, Pre: 0.92737430, F1:0.96231884, vp:  498; vn:  459; fp:   39; fn:    0\n","2021-10-12 11:27:46,957 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f2_BERTimbau_base, Data: 18/09/2021 00:37, Tempo: 0:14:27, QtdeTeste: 996, Acc: 0.95281124, Rec: 0.99397590, Pre: 0.91836735, F1:0.95467695, vp:  495; vn:  454; fp:   44; fn:    3\n","2021-10-12 11:27:46,961 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f2_BERTimbau_base, Data: 21/09/2021 02:33, Tempo: 0:15:06, QtdeTeste: 996, Acc: 0.95281124, Rec: 0.99397590, Pre: 0.91836735, F1:0.95467695, vp:  495; vn:  454; fp:   44; fn:    3\n","2021-10-12 11:27:46,968 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f2_BERTimbau_base, Data: 12/10/2021 09:12, Tempo: 0:15:19, QtdeTeste: 996, Acc: 0.95180723, Rec: 0.98795181, Pre: 0.92134831, F1:0.95348837, vp:  492; vn:  456; fp:   42; fn:    6\n","2021-10-12 11:27:46,978 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f3_BERTimbau_base, Data: 18/09/2021 00:53, Tempo: 0:14:26, QtdeTeste: 996, Acc: 0.93975904, Rec: 1.00000000, Pre: 0.89247312, F1:0.94318182, vp:  498; vn:  438; fp:   60; fn:    0\n","2021-10-12 11:27:46,979 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f3_BERTimbau_base, Data: 21/09/2021 02:50, Tempo: 0:15:08, QtdeTeste: 996, Acc: 0.93975904, Rec: 1.00000000, Pre: 0.89247312, F1:0.94318182, vp:  498; vn:  438; fp:   60; fn:    0\n","2021-10-12 11:27:46,984 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f3_BERTimbau_base, Data: 12/10/2021 09:29, Tempo: 0:15:18, QtdeTeste: 996, Acc: 0.94678715, Rec: 1.00000000, Pre: 0.90381125, F1:0.94947569, vp:  498; vn:  445; fp:   53; fn:    0\n","2021-10-12 11:27:46,993 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f4_BERTimbau_base, Data: 18/09/2021 01:09, Tempo: 0:14:27, QtdeTeste: 996, Acc: 0.94979920, Rec: 0.98795181, Pre: 0.91791045, F1:0.95164410, vp:  492; vn:  454; fp:   44; fn:    6\n","2021-10-12 11:27:46,995 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f4_BERTimbau_base, Data: 21/09/2021 03:07, Tempo: 0:15:09, QtdeTeste: 996, Acc: 0.94979920, Rec: 0.98795181, Pre: 0.91791045, F1:0.95164410, vp:  492; vn:  454; fp:   44; fn:    6\n","2021-10-12 11:27:46,998 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f4_BERTimbau_base, Data: 12/10/2021 09:46, Tempo: 0:15:19, QtdeTeste: 996, Acc: 0.94176707, Rec: 0.99196787, Pre: 0.90145985, F1:0.94455067, vp:  494; vn:  444; fp:   54; fn:    4\n","2021-10-12 11:27:47,011 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f5_BERTimbau_base, Data: 18/09/2021 01:25, Tempo: 0:14:19, QtdeTeste: 996, Acc: 0.92269076, Rec: 0.99598394, Pre: 0.86865149, F1:0.92797007, vp:  496; vn:  423; fp:   75; fn:    2\n","2021-10-12 11:27:47,016 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f5_BERTimbau_base, Data: 21/09/2021 03:24, Tempo: 0:15:10, QtdeTeste: 996, Acc: 0.92269076, Rec: 0.99598394, Pre: 0.86865149, F1:0.92797007, vp:  496; vn:  423; fp:   75; fn:    2\n","2021-10-12 11:27:47,019 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f5_BERTimbau_base, Data: 12/10/2021 10:03, Tempo: 0:15:22, QtdeTeste: 996, Acc: 0.92771084, Rec: 1.00000000, Pre: 0.87368421, F1:0.93258427, vp:  498; vn:  426; fp:   72; fn:    0\n","2021-10-12 11:27:47,031 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f6_BERTimbau_base, Data: 21/09/2021 03:41, Tempo: 0:15:09, QtdeTeste: 996, Acc: 0.94879518, Rec: 1.00000000, Pre: 0.90710383, F1:0.95128940, vp:  498; vn:  447; fp:   51; fn:    0\n","2021-10-12 11:27:47,033 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f6_BERTimbau_base, Data: 12/10/2021 10:19, Tempo: 0:15:23, QtdeTeste: 996, Acc: 0.94176707, Rec: 0.98594378, Pre: 0.90590406, F1:0.94423077, vp:  491; vn:  447; fp:   51; fn:    7\n","2021-10-12 11:27:47,045 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f7_BERTimbau_base, Data: 21/09/2021 03:58, Tempo: 0:15:05, QtdeTeste: 996, Acc: 0.93373494, Rec: 0.99397590, Pre: 0.88709677, F1:0.93750000, vp:  495; vn:  435; fp:   63; fn:    3\n","2021-10-12 11:27:47,047 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f7_BERTimbau_base, Data: 12/10/2021 10:37, Tempo: 0:15:20, QtdeTeste: 996, Acc: 0.93273092, Rec: 0.99397590, Pre: 0.88550984, F1:0.93661306, vp:  495; vn:  434; fp:   64; fn:    3\n","2021-10-12 11:27:47,058 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f8_BERTimbau_base, Data: 21/09/2021 04:15, Tempo: 0:15:05, QtdeTeste: 996, Acc: 0.93875502, Rec: 0.98795181, Pre: 0.89945155, F1:0.94162679, vp:  492; vn:  443; fp:   55; fn:    6\n","2021-10-12 11:27:47,060 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f8_BERTimbau_base, Data: 12/10/2021 10:54, Tempo: 0:15:20, QtdeTeste: 996, Acc: 0.92269076, Rec: 0.95582329, Pre: 0.89642185, F1:0.92517007, vp:  476; vn:  443; fp:   55; fn:   22\n","2021-10-12 11:27:47,075 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f9_BERTimbau_base, Data: 12/10/2021 11:10, Tempo: 0:15:20, QtdeTeste: 996, Acc: 0.94578313, Rec: 0.99598394, Pre: 0.90510949, F1:0.94837476, vp:  496; vn:  446; fp:   52; fn:    2\n","2021-10-12 11:27:47,083 : INFO : Arquivo: cohebert_AjusteFinoCSTNews_v1_C_SB_KF_E_4_lr_5_b_4_8_f10_BERTimbau_base, Data: 12/10/2021 11:27, Tempo: 0:15:19, QtdeTeste: 996, Acc: 0.95983936, Rec: 0.99196787, Pre: 0.93207547, F1:0.96108949, vp:  494; vn:  462; fp:   36; fn:    4\n","2021-10-12 11:27:47,085 : INFO : Total acurácia                                       : 9.46485944.\n","2021-10-12 11:27:47,087 : INFO : Quantidade de folds                                  : 10.\n","2021-10-12 11:27:47,091 : INFO : A média da acurácia de 10 folds é                    : 0.94648594.\n","2021-10-12 11:27:47,093 : INFO : O tempo gasto na execução do treinamentoa 10 folds é : 05:46:13.\n","2021-10-12 11:27:47,097 : INFO : A média de tempo de execução de 10 folds é           : 00:15:03.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Q_zqfWmlIjMc"},"source":["## 6.1 Salvando o Modelo para o wandb"]},{"cell_type":"code","metadata":{"id":"U9U-parMIj00","executionInfo":{"status":"ok","timestamp":1634038067791,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["if model_args.use_wandb and model_args.salvar_modelo_wandb:\n","  \n","    # Salva o modelo para o wandb    \n","    torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model_dict.pt'))"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2079Qyn8Mt8"},"source":["## 6.2 Salvando o Modelo Ajustado\n","\n","Grava o modelo e o tokenizador no disco."]},{"cell_type":"code","metadata":{"id":"6ulTWaOr8QNY","executionInfo":{"status":"ok","timestamp":1634038067792,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["def salvaModelo(model_args):\n","  \n","    if model_args.salvar_modelo:\n","  \n","        # Import de bibliotecas.\n","        import os\n","\n","        # Salvando as melhores práticas: se você usar nomes padrão para o modelo, você pode recarregá-lo usando from_pretrained ()\n","\n","        # Diretório de salvamento do modelo.\n","        DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/'\n","\n","        # Cria o diretório de saída se necessário.\n","        if not os.path.exists(DIRETORIO_LOCAL_MODELO_AJUSTADO):\n","            os.makedirs(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","        print('Salvando o modelo para {}'.format(DIRETORIO_LOCAL_MODELO_AJUSTADO))\n","\n","        # Salve um modelo treinado, configuração e tokenizer usando `save_pretrained ()`.\n","        # Eles podem então ser recarregados usando `from_pretrained ()`.\n","        model_to_save = model.module if hasattr(model, 'module') else model  # Cuide do treinamento distribuído/paralelo\n","        model_to_save.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","        tokenizer.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","        # Boa prática: salve seus argumentos de treinamento junto com o modelo treinado.\n","        torch.save (model_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'model_args.bin'))\n","        torch.save (training_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'training_args.bin'))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4x5HZvCx1M5","executionInfo":{"status":"ok","timestamp":1634038067792,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["salvaModelo(model_args)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-tjHkR7lc1I"},"source":["Vamos verificar os tamanhos dos arquivos."]},{"cell_type":"code","metadata":{"id":"mqMzI3VTCZo5","executionInfo":{"status":"ok","timestamp":1634038067793,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=K /content/modelo_ajustado/"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fr_bt2rFlgDn"},"source":["O maior arquivo é o peso do modelo, em torno de 416MB o base e 1.25G o large."]},{"cell_type":"code","metadata":{"id":"-WUFUIQ8Cu8D","executionInfo":{"status":"ok","timestamp":1634038067793,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["if model_args.salvar_modelo:\n","  !ls -l --block-size=M /content/modelo_ajustado/pytorch_model.bin"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dzGKvOFAll_e"},"source":["Para salvar seu modelo nas sessões do Colab Notebook, faça o download no seu computador local ou, idealmente, copie-o no seu Google Drive."]},{"cell_type":"code","metadata":{"id":"NxlZsafTC-V5","executionInfo":{"status":"ok","timestamp":1634038067793,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["if model_args.salvar_modelo:\n","\n","  # Importando as bibliotecas.\n","  import os\n","\n","  # Import de bibliotecas\n","  from bert.bertmodulo import *\n","\n","  # Verifica o nome do modelo BERT a ser utilizado\n","  MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","  # Verifica o tamanho do modelo(default large)\n","  TAMANHO_BERT =  getTamanhoBERT(model_args)\n","  \n","  # Diretório local de salvamento do modelo.\n","  DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/'\n","\n","  # Diretório remoto de salvamento do modelo.  \n","  DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/kfold/modelo/modelo\" + MODELO_BERT + TAMANHO_BERT\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_REMOTO_MODELO_AJUSTADO):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_REMOTO_MODELO_AJUSTADO)\n","    print('Diretório criado: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","  else:\n","    print('Diretório já existe: {}'.format(DIRETORIO_REMOTO_MODELO_AJUSTADO))\n","\n","  ## Copia o arquivo do modelo para o diretório no Google Drive.\n","  !cp -r '$DIRETORIO_LOCAL_MODELO_AJUSTADO'* '$DIRETORIO_REMOTO_MODELO_AJUSTADO'\n","\n","  print(\"Modelo copiado!\")"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.3 Tempo final de processamento\n","\n"]},{"cell_type":"code","metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634038068825,"user_tz":180,"elapsed":1045,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"4fd08a4b-5ff5-4a2b-e7d1-7927341fc331"},"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","finalProcessamento = time.time()\n","tempoTotalProcessamento = formataTempo(finalProcessamento - inicioProcessamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento: {:} (h:mm:ss)\".format(tempoTotalProcessamento))"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento: 2:51:13 (h:mm:ss)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CeSarQ7N0su4"},"source":["Executa o wandb para finalizar a execução anterior"]},{"cell_type":"code","metadata":{"id":"QIsky8teJ_ki","executionInfo":{"status":"ok","timestamp":1634038068826,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}}},"source":["if model_args.use_wandb:\n","    # Importando a biblioteca.\n","    import wandb\n","    \n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=\"ajustefinocstnews_v1_c_sb_kfold\", name=training_args.output_dir + str(model_args.fold))"],"execution_count":26,"outputs":[]}]}